{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 000 Forecasting Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from https://colab.research.google.com/drive/1_Il5h2Ed4zFa6Z3bROVCE68LZcSi4wHX?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-08-02'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "today = str(datetime.datetime.now())[0:10]\n",
    "today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 000_bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run this notebook as is, you'll need to enter a few API keys (use the key icon on the left to input them):\n",
    "\n",
    "- `METACULUS_TOKEN`: you can find your Metaculus token under your bot's user settings page: https://www.metaculus.com/accounts/settings/, or on the bot registration page where you created the account: https://www.metaculus.com/aib/\n",
    "- `OPENAPI_API_KEY`: get one from OpenAIs page: https://platform.openai.com/settings/profile?tab=api-keys\n",
    "- `PERPLEXITY_API_KEY` - used to search up-to-date information about the question. Get one from https://www.perplexity.ai/settings/api\n",
    "- `ASKNEWS_CLIENT_ID`, `ASKNEWS_SECRET`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "token_fn = \"tokens.yaml\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tokens = OmegaConf.create(\"\"\"\n",
    "METACULUS_TOKEN: xx\n",
    "OPENAI_API_KEY: yy\n",
    "OPENAI_MODEL: gpt-4o\n",
    "PERPLEXITY_API_KEY: zz\n",
    "PERPLEXITY_MODEL: llama-3-sonar-large-32k-online\"\"\")\n",
    "OmegaConf.save(config=tokens, f=token_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load(token_fn)\n",
    "\n",
    "def pr(tokens):\n",
    "    print(OmegaConf.to_yaml(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDukuXArbgdm",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### LLM and Metaculus Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDukuXArbgdm"
   },
   "source": [
    "This section sets up some simple helper code you can use to get data about forecasting questions and to submit a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HifodCwcGU0j"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HifodCwcGU0j"
   },
   "outputs": [],
   "source": [
    "AUTH_HEADERS = {\"headers\": {\"Authorization\": f\"Token {config.METACULUS_TOKEN}\"}}\n",
    "API_BASE_URL = \"https://www.metaculus.com/api2\"\n",
    "WARMUP_TOURNAMENT_ID = 3349\n",
    "SUBMIT_PREDICTION = True\n",
    "\n",
    "def find_number_before_percent(s):\n",
    "    # Use a regular expression to find all numbers followed by a '%'\n",
    "    matches = re.findall(r'(\\d+)%', s)\n",
    "    if matches:\n",
    "        # Return the last number found before a '%'\n",
    "        return int(matches[-1])\n",
    "    else:\n",
    "        # Return None if no number found\n",
    "        return None\n",
    "\n",
    "def post_question_comment(question_id, comment_text):\n",
    "    \"\"\"\n",
    "    Post a comment on the question page as the bot user.\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.post(\n",
    "        f\"{API_BASE_URL}/comments/\",\n",
    "        json={\n",
    "            \"comment_text\": comment_text,\n",
    "            \"submit_type\": \"N\",\n",
    "            \"include_latest_prediction\": True,\n",
    "            \"question\": question_id,\n",
    "        },\n",
    "        **AUTH_HEADERS,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    print(\"Comment posted for \", question_id)\n",
    "\n",
    "def post_question_prediction(question_id, prediction_percentage):\n",
    "    \"\"\"\n",
    "    Post a prediction value (between 1 and 100) on the question.\n",
    "    \"\"\"\n",
    "    url = f\"{API_BASE_URL}/questions/{question_id}/predict/\"\n",
    "    response = requests.post(\n",
    "        url,\n",
    "        json={\"prediction\": float(prediction_percentage) / 100},\n",
    "        **AUTH_HEADERS,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    print(\"Prediction posted for \", question_id)\n",
    "\n",
    "\n",
    "def get_question_details(question_id):\n",
    "    \"\"\"\n",
    "    Get all details about a specific question.\n",
    "    \"\"\"\n",
    "    url = f\"{API_BASE_URL}/questions/{question_id}/\"\n",
    "    response = requests.get(\n",
    "        url,\n",
    "        **AUTH_HEADERS,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    return json.loads(response.content)\n",
    "\n",
    "def list_questions(tournament_id=WARMUP_TOURNAMENT_ID, offset=0, count=1000):\n",
    "    \"\"\"\n",
    "    List (all details) {count} questions from the {tournament_id}\n",
    "    \"\"\"\n",
    "    url_qparams = {\n",
    "        \"limit\": count,\n",
    "        \"offset\": offset,\n",
    "        \"has_group\": \"false\",\n",
    "        \"order_by\": \"-activity\",\n",
    "        \"forecast_type\": \"binary\",\n",
    "        \"project\": tournament_id,\n",
    "        \"status\": \"open\",\n",
    "        \"type\": \"forecast\",\n",
    "        \"include_description\": \"true\",\n",
    "    }\n",
    "    url = f\"{API_BASE_URL}/questions/\"\n",
    "    response = requests.get(url, **AUTH_HEADERS, params=url_qparams)\n",
    "    response.raise_for_status()\n",
    "    data = json.loads(response.content)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### IFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IFP:\n",
    "\n",
    "    def __init__(self, question_id):\n",
    "        self.question_id = question_id\n",
    "        self.question_details = get_question_details(self.question_id)\n",
    "        self.today = datetime.datetime.now().strftime(\"%Y-%m-%d\")   \n",
    "        self.title = self.question_details[\"title\"]\n",
    "        self.resolution_criteria = self.question_details[\"resolution_criteria\"]\n",
    "        self.background = self.question_details[\"description\"]\n",
    "        self.fine_print = self.question_details[\"fine_print\"]\n",
    "\n",
    "    def report(self):\n",
    "        rpt = f\"\"\"\n",
    "The future event is described by this question: [ {self.title} ]\n",
    "The resolution criteria are: [ {self.resolution_criteria} ]\n",
    "The background is: [ {self.background} ]\"\"\"\n",
    "        if self.fine_print:\n",
    "            rpt += f\"\"\"\n",
    "The fine print is: [ {self.fine_print} ]\"\"\"\n",
    "        return rpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### In general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM:\n",
    "    def __init__(self, system_role):\n",
    "        self.messages = [{\"role\": \"system\", \"content\": system_role}]\n",
    "\n",
    "    def chat(self, query):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": query})\n",
    "        text = self.message()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": text})\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### MetaAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pypi.org/project/meta-ai-api/1.0.6/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " from meta_ai_api import MetaAI as mai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaAI(LLM):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.ai = mai()\n",
    "        super().__init__('MetaAI')\n",
    "        \n",
    "    def message(self):\n",
    "        return self.ai.prompt(message=self.messages[-1]['content'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ai = MetaAI()\n",
    "ai.chat('Bruce Bueno de Mesquita')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### HuggingChat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pypi.org/project/hugchat/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hugchat import hugchat\n",
    "from hugchat.login import Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuggingChat(LLM):\n",
    "\n",
    "    def __init__(self):\n",
    "        # Log in to huggingface and grant authorization to huggingchat\n",
    "        EMAIL = config.HUGGINGFACE_USERNAME\n",
    "        PASSWD = config.HUGGINGFACE_PASSWORD\n",
    "        cookie_path_dir = \"./cookies/\" # NOTE: trailing slash (/) is required to avoid errors\n",
    "        sign = Login(EMAIL, PASSWD)\n",
    "        cookies = sign.login(cookie_dir_path=cookie_path_dir, save_cookies=True)\n",
    "        self.chatbot = hugchat.ChatBot(cookies=cookies.get_dict()) \n",
    "        super().__init__('HuggingChat')\n",
    "        \n",
    "    def message(self):\n",
    "        result = ''.join([x['token'] for x in self.chatbot.chat(self.messages[-1]['content']) if x])\n",
    "        return result\n",
    "\n",
    "    def web_search(self, query):\n",
    "        query_result = self.chatbot.query(query, web_search=True)\n",
    "        return query_result\n",
    "        print(query_result)\n",
    "        for source in query_result.web_search_sources:\n",
    "            print(source.link)\n",
    "            print(source.title)\n",
    "            print(source.hostname)\n",
    "\n",
    "    def available_models(self):\n",
    "        return [(i,str(x)) for i,x in enumerate(self.chatbot.get_available_llm_models())]\n",
    "\n",
    "    def switch_llm(self, i):\n",
    "        self.chatbot.switch_llm(i)\n",
    "\n",
    "    def conversation_info(self):\n",
    "        info = self.chatbot.get_conversation_info()\n",
    "        # print(info.id, info.title, info.model, info.system_prompt, info.history)\n",
    "        return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = HuggingChat()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hc.chat('Bruce Bueno de Mesquita')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hc.available_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Metaculus Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class Claude(LLM):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__('Claude')\n",
    "        \n",
    "    def message(self):\n",
    "        content = self.messages[-1]['content']\n",
    "        url = \"https://www.metaculus.com/proxy/anthropic/v1/messages\"\n",
    "        headers =  {\"Authorization\": f\"Token {config.METACULUS_TOKEN}\",\n",
    "                    \"anthropic-version\": \"2023-06-01\",\n",
    "                    \"content-type\": \"application/json\"}\n",
    "        data = {\"model\": \"claude-3-5-sonnet-20240620\",\n",
    "                \"max_tokens\": 1024,\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": content}]}\n",
    "        response = requests.post(url, headers=headers, data = json.dumps(data))\n",
    "        # Check the response status code\n",
    "        if response.status_code != 200:\n",
    "            print(\"Request failed with status code\", response.status_code)\n",
    "            print(response.text)\n",
    "        return response.json()['content'][0]['text']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "claude = Claude()\n",
    "claude.chat('Bruce Bueno de Mesquita')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AskNews"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install asknews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/drive/1tc383HraMZOiyfKFF1EXAtlTYbsuv3Q5?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asknews_sdk import AskNewsSDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class AskNews(LLM):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__('AskNews')\n",
    "        ASKNEWS_CLIENT_ID = config.ASKNEWS_CLIENT_ID\n",
    "        ASKNEWS_SECRET = config.ASKNEWS_SECRET\n",
    "        \n",
    "        self.ask = AskNewsSDK(\n",
    "              client_id=config.ASKNEWS_CLIENT_ID,\n",
    "              client_secret=config.ASKNEWS_SECRET,\n",
    "              scopes=[\"news\"]\n",
    "          )\n",
    "        \n",
    "    def message(self):\n",
    "        query = self.messages[-1]['content']\n",
    "        return self.ask.news.search_news(query).as_string"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ask = AskNews()\n",
    "print(ask.chat('Bruce Bueno de Mesquita'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = ask.chat('Bruce Bueno de Mesquita')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perplexity(LLM):\n",
    "    def message(self):\n",
    "        url = \"https://api.perplexity.ai/chat/completions\"\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"authorization\": f\"Bearer {config.PERPLEXITY_API_KEY}\",\n",
    "            \"content-type\": \"application/json\"  }\n",
    "        payload = {\"model\": config.PERPLEXITY_MODEL, \"messages\": self.messages }\n",
    "        response = requests.post(url=url, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Metaculus OpenAI"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import json\n",
    "\n",
    "class MetacGPT(LLM):\n",
    "\n",
    "    def __init__(self, system_role):\n",
    "        super().__init__(system_role)\n",
    "        \n",
    "    def message(self):\n",
    "        content = self.messages[-1]['content']\n",
    "        url = \"https://www.metaculus.com/proxy/openai/v1/chat/completions\"\n",
    "        headers =  {\"Authorization\": f\"Token {config.METACULUS_TOKEN}\",\n",
    "                    \"content-type\": \"application/json\"}\n",
    "        data = {\"model\": \"gpt-3.5-turbo\",\n",
    "                \"max_tokens\": 1024,\n",
    "                \"messages\": self.messages}\n",
    "        response = requests.post(url, headers=headers, data = json.dumps(data))\n",
    "        # Check the response status code\n",
    "        if response.status_code != 200:\n",
    "            print(\"Request failed with status code\", response.status_code)\n",
    "            print(response.text)\n",
    "        return response.json()['content'][0]['text']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mgpt = MetacGPT('You are a helpful assistant')\n",
    "mgpt.chat('Bruce Bueno de Mesquita')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatGPT(LLM):\n",
    "    def __init__(self, system_role):\n",
    "        super().__init__(system_role)\n",
    "        self.client = OpenAI(api_key=config.OPENAI_API_KEY)\n",
    "\n",
    "    def message(self):\n",
    "        chat_completion = self.client.chat.completions.create(\n",
    "            model=config.OPENAI_MODEL,\n",
    "            messages= self.messages)\n",
    "        return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Test questions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "jul25 = [26638, 26639, 26640, 26641, 26642, 26643, 26644, 26645, 26646]\n",
    "\n",
    "ifps = {id: IFP(id) for id in jul25}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WUvm1tVmMkO",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, system_role, llm):\n",
    "        self.llm = llm(system_role)\n",
    "\n",
    "    def chat(self, prompt):\n",
    "        return self.llm.chat(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Rate Analyzer(TBD: ChatGPT is better)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class RateAnalyzer(Agent):\n",
    "    def __init__(self, llm):\n",
    "        self.system_role = f\"\"\"\n",
    "A question about an event is formatted as |id|question|criteria|background|fineprint|.\n",
    "Today's date is {today}.\n",
    "You will report \n",
    "1. today's date, \n",
    "2. the end date of the question, \n",
    "3. the time in days D from today to end date, \n",
    "4. the daily rate of change R of the quantity,\n",
    "5. today's value V of the quantity,\n",
    "6. the change in value dV of the quantity = D * r,\n",
    "7. the final value of the quantity F = V + dV.  Give your best estimate.\n",
    "\"\"\"\n",
    "        super().__init__(self.system_role, llm)\n",
    "\n",
    "    def recherche(self, ifp):\n",
    "        prompt = f\"|{ifp.question_id}|{ifp.title}|{ifp.resolution_criteria}|{ifp.background}|{ifp.fine_print}|\"\n",
    "        self.R = self.chat(prompt)\n",
    "        ifp.rates = self.R\n",
    "        print(ifp.question_id, ifp.title)\n",
    "        print(self.R)\n",
    "\n",
    "    def analyze(self, ifps):\n",
    "        for ifp in tqdm(ifps):\n",
    "            self.recherche(ifps[ifp])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rates = RateAnalyzer(Perplexity)\n",
    "rates.analyze(ifps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Newser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Newser(Agent):\n",
    "    def __init__(self):\n",
    "        self.ask = AskNews()\n",
    "\n",
    "    def recherche(self, ifp):\n",
    "        ifp.news = self.ask.chat(ifp.title)\n",
    "\n",
    "    def research(self, ifps):\n",
    "        for ifp in tqdm(ifps):\n",
    "            self.recherche(ifps[ifp])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "newser = Newser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Researcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Researcher(Agent):\n",
    "    def __init__(self, llm):\n",
    "        self.system_role = f\"\"\"\n",
    "You are an open source intelligence analyst.\n",
    "You summarize news related to questions about events.\n",
    "A question about an event is formatted as |id|question|criteria|background|fineprint|.\n",
    "You will find on the web and report any reliable information you can gather about the question.\n",
    "Do not make an assessment of probability.\n",
    "Do not repeat information provided to you already in the prompt.\"\"\"\n",
    "        super().__init__(self.system_role, llm)\n",
    "\n",
    "    def recherche(self, ifp):\n",
    "        prompt = f\"|{ifp.question_id}|{ifp.title}|{ifp.resolution_criteria}|{ifp.background}|{ifp.fine_print}|\"\n",
    "        self.R = self.chat(prompt)\n",
    "        ifp.news = self.R\n",
    "        print(ifp.question_id, ifp.title)\n",
    "        print(self.R)\n",
    "\n",
    "    def research(self, ifps):\n",
    "        for ifp in tqdm(ifps):\n",
    "            self.recherche(ifps[ifp])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "researcher = Researcher(ChatGPT)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "researcher.research(ifps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question relator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionRelator(Agent):\n",
    "    def __init__(self, llm):\n",
    "        self.system_role = f\"\"\"\n",
    "You are prompted with list of forecasting questions, each with an id and a title.\n",
    "Label each question with an underlying event.\n",
    "If the questions are for the same event, use the same name for the underlying event.\n",
    "Please return as separate lines formatted as |event|id|title|, do not add any other formatting.\n",
    "\"\"\"\n",
    "        super().__init__(self.system_role, llm)\n",
    "\n",
    "    def relate(self, ifps):\n",
    "        prompt = '\\n'.join([f\"{ifp.question_id}: {ifp.title}\" for ifp in ifps.values()])\n",
    "        KL = self.chat(prompt)\n",
    "        K1 = [x.split('|') for x in KL.split('\\n')]\n",
    "        K2 = [(int(id),event) for _,event,id,_,_ in K1]\n",
    "        for id,event in K2:\n",
    "            ifps[id].event = event\n",
    "            print(id, event)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "qr = QuestionRelator(ChatGPT)\n",
    "qr.relate(ifps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Superforecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Superforecaster(Agent):\n",
    "    def __init__(self, llm):\n",
    "        self.system_role = f\"\"\"\n",
    "You are a superforecaster.  \n",
    "You assign a probability to questions about events.\n",
    "Questions are given as separate groups of lines formatted as |FORECAST|event|id|question|news|criteria|background|fineprint|.\n",
    "Groups are separated by '^^^'.\n",
    "Questions which are about the same event should be assigned consistent probabilities.\n",
    "Reply to questions with |ASSESSMENT|id|ZZ|rationale| where ZZ is an integer probability from 1 to 99 and rationale is your reasoning for the forecast.\n",
    "Separate each question with '^^^'.\n",
    "Do not add any additional headings or group labels or other formatting.\n",
    "After your initial forecast you may receive feedback of form |CRITIC|id|feedback|.\n",
    "Reply to each feedback with |id|ZZ|rationale| where ZZ is an integer probability from 1 to 99 and \n",
    "and rationale is a revised assessment which may be adjusted from a prior assessment due the feedback unless the feedback is \"I concur\".\n",
    "\"\"\"\n",
    "        super().__init__(self.system_role, llm)\n",
    "\n",
    "    def forecast(self, ifps):\n",
    "        prompt = '^^^'.join([f\"FORECAST|{ifp.event}|{ifp.question_id}|{ifp.news}|{ifp.resolution_criteria}|{ifp.background}|{ifp.fine_print}|\" for ifp in ifps.values()])\n",
    "        self.F0 = self.chat(prompt)\n",
    "        self.F1 = [x.strip().replace('\\n', '') for x in self.F0.split('^^^')]\n",
    "        self.F2 = [x.split('|') for x in self.F1] \n",
    "        self.F3 = [[x for x in y if x] for y in self.F2]\n",
    "        self.F4 = [(int(id),int(forecast),rationale) for _, id, forecast, rationale in self.F3]\n",
    "        for id, forecast, rationale in self.F4:\n",
    "            ifps[id].forecast = forecast\n",
    "            ifps[id].rationale = rationale\n",
    "            print(id, forecast, rationale)\n",
    "\n",
    "    def reassess(self, ifp):\n",
    "        prompt = f\"|CRITIC|{ifp.question_id}|{ifp.feedback}|\"\n",
    "        self.R0 = self.chat(prompt)\n",
    "        id,fcst,rationale = [x for x in self.R0.strip().split('|') if x]\n",
    "        id = int(id)\n",
    "        fcst = int(fcst)\n",
    "        ifps[id].forecast = fcst\n",
    "        ifps[id].rationale = rationale\n",
    "        print(id, fcst, rationale)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sf = Superforecaster(ChatGPT)\n",
    "\n",
    "sf.forecast(ifps)\n",
    "\n",
    "for ifp in ifps.values():\n",
    "    if ifp.feedback != 'I concur':\n",
    "        sf.reassess(ifp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic (Agent):\n",
    "    def __init__(self, llm):\n",
    "\n",
    "        self.system_role = f\"\"\"\n",
    "You a very smart and worldly person reviewing a superforecaster's assignment of probabilities to events.\n",
    "You will receive an event with probabilities given as |event|id|question|zz|rationale|news|criteria|background|fineprint|.\n",
    "zz is an integer probability from 1 to 99 and rationale is the student's logic for assigning probability of zz.\n",
    "You will reply with a line |id|feedback| where feedback is \"I concur\" if you see no problem with the rationale and zz otherwise presents possible problems with the rationale and zz.\n",
    "\"\"\"\n",
    "        super().__init__(self.system_role, llm)\n",
    "\n",
    "    def feedback(self, ifp):\n",
    "        prompt = f\"|{ifp.event}|{ifp.question_id}|{ifp.title}|{ifp.forecast}|{ifp.rationale}|{ifp.news}|{ifp.resolution_criteria}|{ifp.background}|{ifp.fine_print}|\"\n",
    "        self.fb = self.chat(prompt)\n",
    "        self.fb1 = self.fb.split('|')\n",
    "        self.fb2 = [x for x in self.fb1 if x]\n",
    "        try:\n",
    "            id,feedback = self.fb2\n",
    "            ifps[int(id)].feedback = feedback\n",
    "            print(id, feedback)\n",
    "        except:\n",
    "            print('problem', self.fb2)\n",
    "            ifps[int(id)].feedback = 'I concur'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "categories = {\"Market Price\": \"The current or future prices or comparative price / value of goods, services, commodities, stocks, treasuries, indices, and other traded financial products. This excludes products which aren't traded and subject to supply and demand.\",\n",
    "                \"Macroeconomics\": \"A quantifiable measure with historical values being above, below, or between values. This includes all-time records, record lows, record highs, or simply exceeding a value at a specified time.\",\n",
    "                \"Epidemic\": \"The rate of spread of a disease\",\n",
    "                \"Disease\": \"A new outbreak of an old or new disease\",\n",
    "                \"Medical Device\": \"Invention or distribution of a new medical device\",\n",
    "                \"Drug Discovery\": \"Invention of a new drug for a specific medical condition\",\n",
    "                \"Civil Unrest\": \"Riots and protests\",\n",
    "                \"Crime\": \"Crime statistics\",\n",
    "                \"Elections\": \"Elections\",\n",
    "                \"Leadership change\": \"Leadership change but not from an election\",\n",
    "                \"Sports\": \"Sporting event outcomes and sport statistics\"}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfc = pd.DataFrame(categories.items())\n",
    "text = \"\"\n",
    "for cat in categories:\n",
    "    descr = categories[cat]\n",
    "    text += f\"* {cat}: {descr}\\n\"\n",
    "dfc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "critic = Critic(Perplexity)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for ifp in ifps.values():\n",
    "    critic.feedback(ifp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add an agent to summarize the back and forth between critic and forecaster into a single cogent rationale that incorporates all that was discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting process"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ifps = {id: IFP(id) for id in jul25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecasting(ifps, use_newser = False):\n",
    "    max_tries = 4\n",
    "\n",
    "    if use_newser:\n",
    "        ask = Newser()\n",
    "        ask.research(ifps)\n",
    "    else:\n",
    "        analyst = Researcher(ChatGPT)\n",
    "        analyst.research(ifps)\n",
    "    \n",
    "    qr = QuestionRelator(ChatGPT)\n",
    "    qr.relate(ifps)\n",
    "    \n",
    "    sf = Superforecaster(ChatGPT)\n",
    "    sf.forecast(ifps)\n",
    "    \n",
    "    for ifp in ifps.values():\n",
    "        print(\"Refining\", ifp.question_id)\n",
    "        ifp.feedback = ''\n",
    "        critic = Critic(Perplexity)\n",
    "        for i in range(max_tries):\n",
    "            print(\"Pass\", i, \"of\", max_tries, \"on\", ifp.question_id)\n",
    "            if 'concur' in ifp.feedback:\n",
    "                print(\"concur 1\")\n",
    "                break\n",
    "            critic.feedback(ifp)\n",
    "            if 'concur' in ifp.feedback:\n",
    "                print(\"concur 2\")\n",
    "                break\n",
    "            sf.reassess(ifp)\n",
    "        print(\"===============================================\")\n",
    "\n",
    "    for ifp in ifps.values():\n",
    "        print(ifp.question_id, ifp.title)\n",
    "        print(\"Forecast\", ifp.forecast)\n",
    "        print(\"Rationale\", ifp.rationale, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload(ifp):\n",
    "    post_question_prediction(ifp.question_id, ifp.forecast)\n",
    "    post_question_comment(ifp.question_id, ifp.rationale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uploads(ifps):\n",
    "    for ifp in ifps.values():\n",
    "        upload(ifp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get IFP ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifps = list_questions()['results']\n",
    "today_ids = list(sorted([x['id'] for x in ifps]))\n",
    "# today_ids = [25876, 25877, 25875, 25873, 25871, 25878, 25874, 25872] # 08JUL24\n",
    "# today_ids = [26006, 25936, 25935, 25934, 25933, 26004, 26005] # 09JUL24\n",
    "# today_ids = [25955, 25956, 25957, 25960, 25959, 25954, 25953, 25952, 25958] # 10JUL24\n",
    "# today_ids = [26019, 26018, 26017, 26020, 26022, 26021, 26023, 26024] # 11JUL24\n",
    "# today_ids = [26095, 26096, 26097, 26098, 26099, 26100, 26101, 26102] # 12JUL24\n",
    "# today_ids = [26133, 26134, 26138, 26139, 26140, 26157, 26158, 26159] # 15JUL24\n",
    "# today_ids = [26189, 26190, 26191, 26192, 26193, 26194, 26195, 26196] # 16JUL24\n",
    "# today_ids = [26210, 26211, 26212, 26213, 26214, 26215, 26216] # 17JUL24\n",
    "# today_ids = [26232, 26233, 26234, 26235, 26236] # 18JUL24\n",
    "# today_ids = [26302, 26303, 26304, 26305, 26306, 26307] # 19JUL24\n",
    "# today_ids = [26387, 26388, 26389, 26390, 26391, 26392] # 22JUL24\n",
    "# today_ids = [26404, 26405, 26406, 26407, 26408] # 23JUL24\n",
    "# today_ids = [26550, 26551, 26552, 26553, 26554, 26555] # 24JUL24\n",
    "# today_ids = [26568, 26569, 26570, 26571, 26572, 26573, 26574, 26575, 26576, 26577] # 25JUL24\n",
    "# today_ids = [26638, 26639, 26640, 26641, 26642, 26643, 26644, 26645, 26646] # 26JUL24\n",
    "# today_ids = [26665, 26666, 26667, 26668, 26669, 26670, 26671, 26683] # 29JUL24\n",
    "# today_ids = [26700, 26701, 26702, 26703, 26704, 26705, 26706] # 30JUL24\n",
    "# today_ids = [26816, 26817, 26818, 26819, 26820, 26821, 26844] # 31JUL24\n",
    "# today_ids = [26771, 26772, 26773, 26774, 26775, 26776, 26777, 26778, 26779, 26780, 26781] # 01AUG24\n",
    "# today_ids = [26837, 26838, 26839, 26840, 26841, 26842] # 02AUG24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26837, 26838, 26839, 26840, 26841, 26842]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today_ids "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifps = {id: IFP(id) for id in today_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████▌                                     | 1/6 [00:02<00:11,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26837 Will \"Woman's World\" by Katy Perry achieve a ranking higher than 15th on the Billboard Hot 100 before October 1, 2024?\n",
      "I will gather the latest information about the current ranking trajectory of \"Woman's World\" by Katy Perry on the Billboard Hot 100 since the time of the prompt (July 26, 2024).\n",
      "\n",
      "Please hold on while I retrieve the latest updates.\n",
      "\n",
      "---\n",
      "\n",
      "As of my 2023 knowledge cutoff and hypothetical tools, the latest Billboard Hot 100 ranking can be accessed by checking the [Billboard Hot 100](https://www.billboard.com/charts/hot-100/) chart.\n",
      "\n",
      "For real-time updates on the ranking of \"Woman's World\" by Katy Perry, you would need to regularly check the Billboard Hot 100 link provided or follow music industry news sources for any breaking updates on the song’s performance. As per your background information, the song was at 63rd position on July 26, 2024. \n",
      "\n",
      "For the final resolution before October 1, 2024, the song must achieve a ranking higher than 15th, and this can be confirmed by continually monitoring its position on the official Billboard Hot 100 chart.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████                              | 2/6 [00:05<00:12,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26838 Will the median net worth on Bloomberg's Billionaires Index be above $10.2 billion on September 16, 2024?\n",
      "To determine whether the median net worth on Bloomberg's Billionaires Index will be above $10.2 billion on September 16, 2024, I need to track recent movements and trends in the net worths of the world's billionaires as presented on the index.\n",
      "\n",
      "Please hold on while I gather the latest updates.\n",
      "\n",
      "---\n",
      "\n",
      "As of the recent data in July 2024, the median net worth on Bloomberg's Billionaires Index stood at $10.0 billion. This implies an upward trend from $9.535 billion in April 2024 to $10.0 billion in July 2024.\n",
      "\n",
      "To resolve this question definitively, you will need to check the median net worth on Bloomberg's Billionaires Index at the specific time and date mentioned on September 16, 2024, after 5:00 PM Eastern Time by following this [link](https://www.bloomberg.com/billionaires/).\n",
      "\n",
      "For continuous updates and to monitor wealthy individuals' positions on the list, regularly visiting the Bloomberg Billionaires Index or trustworthy financial news sources can provide the latest information and projections.\n",
      "\n",
      "Summarizing:\n",
      "- Current median net worth trends show an increase.\n",
      "- The final determination requires checking Bloomberg's Billionaires Index on the specified date and time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████▌                      | 3/6 [00:08<00:09,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26839 Will Apple announce an iPhone with stacked battery technology before October 1, 2024?\n",
      "\n",
      "To find out whether Apple will announce an iPhone with stacked battery technology before October 1, 2024, I will search for the latest news and official statements regarding upcoming iPhone models.\n",
      "\n",
      "Please hold on while I gather the latest updates from reliable sources.\n",
      "\n",
      "---\n",
      "\n",
      "Based on the available sources and rumors:\n",
      "\n",
      "1. **MacRumors**: Reports suggest that the iPhone 16 Pro models might feature stacked battery technology.\n",
      "2. **Other Sources**: Additional tech news sources and Apple-related rumor roundups often provide insights into expected announcements and technological advancements.\n",
      "\n",
      "To conclusively resolve this question:\n",
      "- Keep an eye on Apple's official announcements, which usually occur during their annual September events.\n",
      "- Follow real-time updates from trusted technology news portals like MacRumors, The Verge, and other industry watchers.\n",
      "\n",
      "Summarizing:\n",
      "- No official announcement has been made yet regarding iPhone models with stacked battery technology.\n",
      "- Monitor sources leading up to October 1, 2024, for any official announcements from Apple regarding the introduction of this technology in new iPhone models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████               | 4/6 [00:12<00:06,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26840 Will Tesla increase its production in Q3 2024 compared with Q2 2024? \n",
      "To determine if Tesla will increase its production in Q3 2024 compared with Q2 2024, I need to gather recent news, anticipations from industry analysts, and potential statements from Tesla.\n",
      "\n",
      "Please hold on while I collect the information.\n",
      "\n",
      "---\n",
      "\n",
      "Based on available sources and industry insights:\n",
      "\n",
      "1. **Historical Trends**: Tesla has a track record of fluctuating production numbers due to various factors, including supply chain issues, factory upgrades, and market demand.\n",
      "2. **Recent Performance**: In Q2 2024, Tesla produced 410,831 vehicles. For Q3 2024 to show an increase, the production number needs to exceed this figure.\n",
      "3. **Statements and Predictions**: Industry analysts and news sources like Electrek, Reuters, and financial analysts generally provide forecasts on Tesla's production expectations.\n",
      "\n",
      "To keep up with Tesla's production numbers:\n",
      "- Monitor Tesla's Investor Relations website, where they report quarterly production and delivery numbers.\n",
      "- Follow industry news from reliable sources for any updates or statements from Tesla.\n",
      "\n",
      "Summarizing:\n",
      "- Tesla needs to report greater than 410,831 vehicles produced in Q3 2024 for this question to resolve as **Yes**.\n",
      "- Official production numbers are typically reported two days after the quarter's end, expected around October 2, 2024.\n",
      "- Keep an eye on Tesla's reporting channels and news updates for the most accurate information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|█████████████████████████████████████▌       | 5/6 [00:17<00:03,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26841 Will Spirit Airlines file for bankruptcy before October 1, 2024?\n",
      "To determine if Spirit Airlines is likely to file for bankruptcy before October 1, 2024, I will search for recent news, financial reports, and relevant statements about the company's financial health and status.\n",
      "\n",
      "Please hold on while I collect the relevant information.\n",
      "\n",
      "---\n",
      "\n",
      "Based on the information:\n",
      "\n",
      "1. **Historical Context**: Spirit Airlines has faced financial difficulties since the start of the COVID-19 pandemic and had a buyout offer from JetBlue rejected by antitrust regulators.\n",
      "2. **Current Financial Status**: The company continues to struggle with declining revenues and negative earnings and cash flows as of Q2 2024.\n",
      "3. **Recent News**: Reviewing recent news articles, financial reports, and statements from Spirit Airlines or industry analysts can provide insight into their immediate financial health and outlook.\n",
      "\n",
      "Specifically:\n",
      "- **Latest Financial Reports**: Check Spirit Airlines' Q2 2024 and any interim financial statements for financial health indicators.\n",
      "- **Analyst Opinions**: Look at recent opinions and analysis from financial analysts regarding the probability of bankruptcy.\n",
      "- **News Articles**: Keep updated with news regarding any significant changes, actions, or statements from Spirit Airlines' management.\n",
      "\n",
      "To continuously monitor Spirit Airlines' financial status:\n",
      "- Follow updates from financial news portals like CNBC, Bloomberg, and Reuters.\n",
      "- Look for any filings with regulatory bodies such as the SEC or direct press releases from Spirit Airlines.\n",
      "\n",
      "Summarizing:\n",
      "- Spirit Airlines needs to file a petition for bankruptcy protection under any chapter of the United States Bankruptcy Code before October 1, 2024, for this question to resolve as **Yes**.\n",
      "- Keep an eye on current financial reports, news, and analyst predictions for any signs pointing towards potential bankruptcy filing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 6/6 [00:20<00:00,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26842 Before October 1, 2024, will OpenAI announce on the news section of its website that it is planning an IPO?\n",
      "To determine if OpenAI will announce on the news section of its website before October 1, 2024, that it is planning an IPO, I will search for recent news and official statements from OpenAI.\n",
      "\n",
      "Please hold on while I gather the relevant information.\n",
      "\n",
      "---\n",
      "\n",
      "Based on the criteria provided:\n",
      "\n",
      "1. **Official Announcements**: The announcement must appear in the [news section of OpenAI's website](https://openai.com/news/).\n",
      "2. **Recent Valuation**: OpenAI was recently valued at $80 billion, and there has been speculation about a potential IPO.\n",
      "3. **Monitoring**: Continual checking of the news section on the OpenAI website and trusted financial news sources for any updates or rumors about an IPO.\n",
      "\n",
      "As of now, there is no specific announcement in the news section of OpenAI's website regarding an IPO.\n",
      "\n",
      "To stay up-to-date:\n",
      "- Check the [News section of OpenAI's website](https://openai.com/news/) regularly.\n",
      "- Follow reputable financial news sources like Bloomberg, Reuters, and TechCrunch for reports on any potential IPO plans.\n",
      "\n",
      "Summarizing:\n",
      "- Watch for any announcements on the specified section of OpenAI’s website.\n",
      "- Ensure the announcement is officially made in that news section before October 1, 2024.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26837 Billboard Rank of \"Woman's World\"\n",
      "26838 Bloomberg's Billionaires Index Median Net Worth\n",
      "26839 Apple iPhone Battery Technology Announcement\n",
      "26840 Tesla Production Increase\n",
      "26841 Spirit Airlines Bankruptcy\n",
      "26842 OpenAI IPO Announcement\n",
      "26837 15 Given the song's poor initial reception and its current position of 63rd on the Billboard Hot 100 as of July 26, 2024, it seems unlikely the song will climb to a position higher than 15th by October 1, 2024. However, there is a possibility that increased media attention or strategic marketing could boost its performance.\n",
      "26838 70 The median net worth on Bloomberg's Billionaires Index has shown a rising trend, moving from $9.535 billion in April 2024 to $10.0 billion in July 2024. If this upward trajectory continues, it is plausible that the median net worth could exceed $10.2 billion by September 16, 2024.\n",
      "26839 40 Although there are rumors suggesting the iPhone 16 Pro models will have stacked battery technology, no official announcement has been made yet. There is some probability that Apple will announce the technology at its annual September event, but without concrete evidence, the likelihood remains moderate.\n",
      "26840 60 Tesla's production numbers have shown variability due to external factors, but considering historical trends and the company's goal to continually increase production, there is a reasonable chance that Q3 2024 production will exceed 410,831 vehicles.\n",
      "26841 55 Spirit Airlines continues to struggle financially with ongoing losses and declining revenues. While bankruptcy is a distinct possibility given these challenges, it is not certain, making it a slightly better than a coin-flip likelihood.\n",
      "26842 30 Despite OpenAI's significant valuation and the speculation around an IPO, there have been no concrete announcements. Given the current status and necessity of an official announcement on a specific website section, the probability is relatively low but not negligible.\n",
      "Refining 26837\n",
      "Pass 0 of 4 on 26837\n",
      "26837 I concur\n",
      "concur 2\n",
      "===============================================\n",
      "Refining 26838\n",
      "Pass 0 of 4 on 26838\n",
      "26838 I concur\n",
      "concur 2\n",
      "===============================================\n",
      "Refining 26839\n",
      "Pass 0 of 4 on 26839\n",
      "26839 I concur\n",
      "concur 2\n",
      "===============================================\n",
      "Refining 26840\n",
      "Pass 0 of 4 on 26840\n",
      "26840 I concur\n",
      "concur 2\n",
      "===============================================\n",
      "Refining 26841\n",
      "Pass 0 of 4 on 26841\n",
      "26841 The rationale is well-supported by the current financial struggles of Spirit Airlines, including ongoing losses and declining revenues. The probability of 55 seems reasonable given the uncertainty surrounding the airline's ability to recover and the potential for bankruptcy. I concur.\n",
      "concur 2\n",
      "===============================================\n",
      "Refining 26842\n",
      "Pass 0 of 4 on 26842\n",
      "26842 I concur\n",
      "concur 2\n",
      "===============================================\n",
      "26837 Will \"Woman's World\" by Katy Perry achieve a ranking higher than 15th on the Billboard Hot 100 before October 1, 2024?\n",
      "Forecast 15\n",
      "Rationale Given the song's poor initial reception and its current position of 63rd on the Billboard Hot 100 as of July 26, 2024, it seems unlikely the song will climb to a position higher than 15th by October 1, 2024. However, there is a possibility that increased media attention or strategic marketing could boost its performance. \n",
      "\n",
      "26838 Will the median net worth on Bloomberg's Billionaires Index be above $10.2 billion on September 16, 2024?\n",
      "Forecast 70\n",
      "Rationale The median net worth on Bloomberg's Billionaires Index has shown a rising trend, moving from $9.535 billion in April 2024 to $10.0 billion in July 2024. If this upward trajectory continues, it is plausible that the median net worth could exceed $10.2 billion by September 16, 2024. \n",
      "\n",
      "26839 Will Apple announce an iPhone with stacked battery technology before October 1, 2024?\n",
      "\n",
      "Forecast 40\n",
      "Rationale Although there are rumors suggesting the iPhone 16 Pro models will have stacked battery technology, no official announcement has been made yet. There is some probability that Apple will announce the technology at its annual September event, but without concrete evidence, the likelihood remains moderate. \n",
      "\n",
      "26840 Will Tesla increase its production in Q3 2024 compared with Q2 2024? \n",
      "Forecast 60\n",
      "Rationale Tesla's production numbers have shown variability due to external factors, but considering historical trends and the company's goal to continually increase production, there is a reasonable chance that Q3 2024 production will exceed 410,831 vehicles. \n",
      "\n",
      "26841 Will Spirit Airlines file for bankruptcy before October 1, 2024?\n",
      "Forecast 55\n",
      "Rationale Spirit Airlines continues to struggle financially with ongoing losses and declining revenues. While bankruptcy is a distinct possibility given these challenges, it is not certain, making it a slightly better than a coin-flip likelihood. \n",
      "\n",
      "26842 Before October 1, 2024, will OpenAI announce on the news section of its website that it is planning an IPO?\n",
      "Forecast 30\n",
      "Rationale Despite OpenAI's significant valuation and the speculation around an IPO, there have been no concrete announcements. Given the current status and necessity of an official announcement on a specific website section, the probability is relatively low but not negligible. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "forecasting(ifps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction posted for  26837\n",
      "Comment posted for  26837\n",
      "Prediction posted for  26838\n",
      "Comment posted for  26838\n",
      "Prediction posted for  26839\n",
      "Comment posted for  26839\n",
      "Prediction posted for  26840\n",
      "Comment posted for  26840\n",
      "Prediction posted for  26841\n",
      "Comment posted for  26841\n",
      "Prediction posted for  26842\n",
      "Comment posted for  26842\n"
     ]
    }
   ],
   "source": [
    "uploads(ifps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(today_ids)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
