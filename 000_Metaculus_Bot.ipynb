{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 000 Forecasting Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from https://colab.research.google.com/drive/1_Il5h2Ed4zFa6Z3bROVCE68LZcSi4wHX?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-08-01'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "today = str(datetime.datetime.now())[0:10]\n",
    "today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 000_bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run this notebook as is, you'll need to enter a few API keys (use the key icon on the left to input them):\n",
    "\n",
    "- `METACULUS_TOKEN`: you can find your Metaculus token under your bot's user settings page: https://www.metaculus.com/accounts/settings/, or on the bot registration page where you created the account: https://www.metaculus.com/aib/\n",
    "- `OPENAPI_API_KEY`: get one from OpenAIs page: https://platform.openai.com/settings/profile?tab=api-keys\n",
    "- `PERPLEXITY_API_KEY` - used to search up-to-date information about the question. Get one from https://www.perplexity.ai/settings/api\n",
    "- `ASKNEWS_CLIENT_ID`, `ASKNEWS_SECRET`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "token_fn = \"tokens.yaml\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tokens = OmegaConf.create(\"\"\"\n",
    "METACULUS_TOKEN: xx\n",
    "OPENAI_API_KEY: yy\n",
    "OPENAI_MODEL: gpt-4o\n",
    "PERPLEXITY_API_KEY: zz\n",
    "PERPLEXITY_MODEL: llama-3-sonar-large-32k-online\"\"\")\n",
    "OmegaConf.save(config=tokens, f=token_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load(token_fn)\n",
    "\n",
    "def pr(tokens):\n",
    "    print(OmegaConf.to_yaml(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDukuXArbgdm"
   },
   "source": [
    "### LLM and Metaculus Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDukuXArbgdm"
   },
   "source": [
    "This section sets up some simple helper code you can use to get data about forecasting questions and to submit a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HifodCwcGU0j"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HifodCwcGU0j"
   },
   "outputs": [],
   "source": [
    "AUTH_HEADERS = {\"headers\": {\"Authorization\": f\"Token {config.METACULUS_TOKEN}\"}}\n",
    "API_BASE_URL = \"https://www.metaculus.com/api2\"\n",
    "WARMUP_TOURNAMENT_ID = 3349\n",
    "SUBMIT_PREDICTION = True\n",
    "\n",
    "def find_number_before_percent(s):\n",
    "    # Use a regular expression to find all numbers followed by a '%'\n",
    "    matches = re.findall(r'(\\d+)%', s)\n",
    "    if matches:\n",
    "        # Return the last number found before a '%'\n",
    "        return int(matches[-1])\n",
    "    else:\n",
    "        # Return None if no number found\n",
    "        return None\n",
    "\n",
    "def post_question_comment(question_id, comment_text):\n",
    "    \"\"\"\n",
    "    Post a comment on the question page as the bot user.\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.post(\n",
    "        f\"{API_BASE_URL}/comments/\",\n",
    "        json={\n",
    "            \"comment_text\": comment_text,\n",
    "            \"submit_type\": \"N\",\n",
    "            \"include_latest_prediction\": True,\n",
    "            \"question\": question_id,\n",
    "        },\n",
    "        **AUTH_HEADERS,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    print(\"Comment posted for \", question_id)\n",
    "\n",
    "def post_question_prediction(question_id, prediction_percentage):\n",
    "    \"\"\"\n",
    "    Post a prediction value (between 1 and 100) on the question.\n",
    "    \"\"\"\n",
    "    url = f\"{API_BASE_URL}/questions/{question_id}/predict/\"\n",
    "    response = requests.post(\n",
    "        url,\n",
    "        json={\"prediction\": float(prediction_percentage) / 100},\n",
    "        **AUTH_HEADERS,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    print(\"Prediction posted for \", question_id)\n",
    "\n",
    "\n",
    "def get_question_details(question_id):\n",
    "    \"\"\"\n",
    "    Get all details about a specific question.\n",
    "    \"\"\"\n",
    "    url = f\"{API_BASE_URL}/questions/{question_id}/\"\n",
    "    response = requests.get(\n",
    "        url,\n",
    "        **AUTH_HEADERS,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    return json.loads(response.content)\n",
    "\n",
    "def list_questions(tournament_id=WARMUP_TOURNAMENT_ID, offset=0, count=1000):\n",
    "    \"\"\"\n",
    "    List (all details) {count} questions from the {tournament_id}\n",
    "    \"\"\"\n",
    "    url_qparams = {\n",
    "        \"limit\": count,\n",
    "        \"offset\": offset,\n",
    "        \"has_group\": \"false\",\n",
    "        \"order_by\": \"-activity\",\n",
    "        \"forecast_type\": \"binary\",\n",
    "        \"project\": tournament_id,\n",
    "        \"status\": \"open\",\n",
    "        \"type\": \"forecast\",\n",
    "        \"include_description\": \"true\",\n",
    "    }\n",
    "    url = f\"{API_BASE_URL}/questions/\"\n",
    "    response = requests.get(url, **AUTH_HEADERS, params=url_qparams)\n",
    "    response.raise_for_status()\n",
    "    data = json.loads(response.content)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IFP:\n",
    "\n",
    "    def __init__(self, question_id):\n",
    "        self.question_id = question_id\n",
    "        self.question_details = get_question_details(self.question_id)\n",
    "        self.today = datetime.datetime.now().strftime(\"%Y-%m-%d\")   \n",
    "        self.title = self.question_details[\"title\"]\n",
    "        self.resolution_criteria = self.question_details[\"resolution_criteria\"]\n",
    "        self.background = self.question_details[\"description\"]\n",
    "        self.fine_print = self.question_details[\"fine_print\"]\n",
    "\n",
    "    def report(self):\n",
    "        rpt = f\"\"\"\n",
    "The future event is described by this question: [ {self.title} ]\n",
    "The resolution criteria are: [ {self.resolution_criteria} ]\n",
    "The background is: [ {self.background} ]\"\"\"\n",
    "        if self.fine_print:\n",
    "            rpt += f\"\"\"\n",
    "The fine print is: [ {self.fine_print} ]\"\"\"\n",
    "        return rpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM:\n",
    "    def __init__(self, system_role):\n",
    "        self.messages = [{\"role\": \"system\", \"content\": system_role}]\n",
    "\n",
    "    def chat(self, query):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": query})\n",
    "        text = self.message()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": text})\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MetaAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pypi.org/project/meta-ai-api/1.0.6/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " from meta_ai_api import MetaAI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ai = MetaAI()\n",
    "response = ai.prompt(message=\"Whats the weather in San Francisco today? And what is the date?\")\n",
    "\n",
    "response.keys()\n",
    "\n",
    "print(response['message'])\n",
    "\n",
    "print(response['sources'])\n",
    "\n",
    "print(response['media'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingChat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pypi.org/project/hugchat/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hugchat import hugchat\n",
    "from hugchat.login import Login"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Log in to huggingface and grant authorization to huggingchat\n",
    "EMAIL = config.HUGGINGFACE_USERNAME\n",
    "PASSWD = config.HUGGINGFACE_PASSWORD\n",
    "cookie_path_dir = \"./cookies/\" # NOTE: trailing slash (/) is required to avoid errors\n",
    "sign = Login(EMAIL, PASSWD)\n",
    "cookies = sign.login(cookie_dir_path=cookie_path_dir, save_cookies=True)\n",
    "\n",
    "# Create your ChatBot\n",
    "chatbot = hugchat.ChatBot(cookies=cookies.get_dict())  # or cookie_path=\"usercookies/<email>.json\"\n",
    "\n",
    "message_result = chatbot.chat(\"Hi!\") # note: message_result is a generator, the method will return immediately.\n",
    "\n",
    "print(message_result)\n",
    "\n",
    "# Non stream\n",
    "message_str: str = message_result.wait_until_done() # you can also print(message_result) directly. \n",
    "# get files(such as images)\n",
    "file_list = message_result.get_files_created() # must call wait_until_done() first!\n",
    "\n",
    "# tips: model \"CohereForAI/c4ai-command-r-plus\" can generate images :)\n",
    "\n",
    "# Stream response\n",
    "for resp in chatbot.query(\n",
    "    \"Hello\",\n",
    "    stream=True\n",
    "):\n",
    "    print(resp)\n",
    "\n",
    "# Web search\n",
    "query_result = chatbot.query(\"Hi!\", web_search=True)\n",
    "print(query_from hugchat import hugchat\n",
    "from hugchat.login import Login\n",
    "\n",
    "# Log in to huggingface and grant authorization to huggingchat\n",
    "EMAIL = \"your email\"\n",
    "PASSWD = \"your password\"\n",
    "cookie_path_dir = \"./cookies/\" # NOTE: trailing slash (/) is required to avoid errors\n",
    "sign = Login(EMAIL, PASSWD)\n",
    "cookies = sign.login(cookie_dir_path=cookie_path_dir, save_cookies=True)\n",
    "\n",
    "# Create your ChatBot\n",
    "chatbot = hugchat.ChatBot(cookies=cookies.get_dict())  # or cookie_path=\"usercookies/<email>.json\"\n",
    "\n",
    "message_result = chatbot.chat(\"Hi!\") # note: message_result is a generator, the method will return immediately.\n",
    "\n",
    "# Non stream\n",
    "message_str: str = message_result.wait_until_done() # you can also print(message_result) directly. \n",
    "# get files(such as images)\n",
    "file_list = message_result.get_files_created() # must call wait_until_done() first!\n",
    "\n",
    "# tips: model \"CohereForAI/c4ai-command-r-plus\" can generate images :)\n",
    "\n",
    "# Stream response\n",
    "for resp in chatbot.query(\n",
    "    \"Hello\",\n",
    "    stream=True\n",
    "):\n",
    "    print(resp)\n",
    "\n",
    "# Web search\n",
    "query_result = chatbot.query(\"Hi!\", web_search=True)\n",
    "print(query_result)\n",
    "for source in query_result.web_search_sources:\n",
    "    print(source.link)\n",
    "    print(source.title)\n",
    "    print(source.hostname)\n",
    "\n",
    "# Create a new conversation\n",
    "chatbot.new_conversation(switch_to = True) # switch to the new conversation\n",
    "\n",
    "# Get conversations on the server that are not from the current session (all your conversations in huggingchat)\n",
    "conversation_list = chatbot.get_remote_conversations(replace_conversation_list=True)\n",
    "# Get conversation list(local)\n",
    "conversation_list = chatbot.get_conversation_list()\n",
    "\n",
    "# Get the available models (not hardcore)\n",
    "models = chatbot.get_available_llm_models()\n",
    "\n",
    "# Switch model with given index\n",
    "chatbot.switch_llm(0) # Switch to the first model\n",
    "chatbot.switch_llm(1) # Switch to the second model\n",
    "\n",
    "# Get information about the current conversation\n",
    "info = chatbot.get_conversation_info()\n",
    "print(info.id, info.title, info.model, info.system_prompt, info.history)\n",
    "\n",
    "# Assistant\n",
    "assistant = chatbot.search_assistant(assistant_name=\"ChatGpt\") # assistant name list in https://huggingface.co/chat/assistants\n",
    "assistant_list = chatbot.get_assistant_list_by_page(page=0)\n",
    "chatbot.new_conversation(assistant=assistant, switch_to=True) # create a new conversation with assistant\n",
    "\n",
    "# [DANGER] Delete all the conversations for the logged in user\n",
    "chatbot.delete_all_conversations()result)\n",
    "for source in query_result.web_search_sources:\n",
    "    print(source.link)\n",
    "    print(source.title)\n",
    "    print(source.hostname)\n",
    "\n",
    "# Create a new conversation\n",
    "chatbot.new_conversation(switch_to = True) # switch to the new conversation\n",
    "\n",
    "# Get conversations on the server that are not from the current session (all your conversations in huggingchat)\n",
    "conversation_list = chatbot.get_remote_conversations(replace_conversation_list=True)\n",
    "# Get conversation list(local)\n",
    "conversation_list = chatbot.get_conversation_list()\n",
    "\n",
    "# Get the available models (not hardcore)\n",
    "models = chatbot.get_available_llm_models()\n",
    "\n",
    "# Switch model with given index\n",
    "chatbot.switch_llm(0) # Switch to the first model\n",
    "chatbot.switch_llm(1) # Switch to the second model\n",
    "\n",
    "# Get information about the current conversation\n",
    "info = chatbot.get_conversation_info()\n",
    "print(info.id, info.title, info.model, info.system_prompt, info.history)\n",
    "\n",
    "# Assistant\n",
    "assistant = chatbot.search_assistant(assistant_name=\"ChatGpt\") # assistant name list in https://huggingface.co/chat/assistants\n",
    "assistant_list = chatbot.get_assistant_list_by_page(page=0)\n",
    "chatbot.new_conversation(assistant=assistant, switch_to=True) # create a new conversation with assistant\n",
    "\n",
    "# [DANGER] Delete all the conversations for the logged in user\n",
    "chatbot.delete_all_conversations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anthropic"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "curl https://www.metaculus.com/proxy/anthropic/v1/messages \\\n",
    "     --header \"Authorization: Token <your metaculus Token>\" \\\n",
    "     --header \"anthropic-version: 2023-06-01\" \\\n",
    "     --header \"content-type: application/json\" \\\n",
    "     --data \\\n",
    "'{\n",
    "    \"model\": \"claude-3-5-sonnet-20240620\",\n",
    "    \"max_tokens\": 1024,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Hello, world\"}\n",
    "    ]\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AskNews"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install asknews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/drive/1tc383HraMZOiyfKFF1EXAtlTYbsuv3Q5?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asknews_sdk import AskNewsSDK"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ASKNEWS_CLIENT_ID = config.ASKNEWS_CLIENT_ID\n",
    "ASKNEWS_SECRET = config.ASKNEWS_SECRET\n",
    "\n",
    "ask = AskNewsSDK(\n",
    "      client_id=config.ASKNEWS_CLIENT_ID,\n",
    "      client_secret=config.ASKNEWS_SECRET,\n",
    "      scopes=[\"news\"]\n",
    "  )\n",
    "\n",
    "\n",
    "query = \"Effect of fed policy on tech sector\"\n",
    "\n",
    "# prompt-optimized string ready to go for any LLM:\n",
    "news_context = ask.news.search_news(query).as_string\n",
    "\n",
    "print(news_context)\n",
    "\n",
    "def get_asknews_context(query):\n",
    "  \"\"\"\n",
    "  Use the AskNews `news` endpoint to get news context for your query.\n",
    "  The full API reference can be found here: https://docs.asknews.app/en/reference#get-/v1/news/search\n",
    "  \"\"\"\n",
    "  ask = AskNewsSDK(\n",
    "      client_id=ASKNEWS_CLIENT_ID,\n",
    "      client_secret=ASKNEWS_SECRET,\n",
    "      scopes=[\"news\"]\n",
    "  )\n",
    "\n",
    "  # # get the latest news related to the query (within the past 48 hours)\n",
    "  hot_response = ask.news.search_news(\n",
    "      query=query, # your natural language query\n",
    "      n_articles=5, # control the number of articles to include in the context\n",
    "      return_type=\"both\",\n",
    "      strategy=\"latest news\" # enforces looking at the latest news only\n",
    "  )\n",
    "\n",
    "  # get context from the \"historical\" database that contains a news archive going back to 2023\n",
    "  historical_response = ask.news.search_news(\n",
    "      query=query,\n",
    "      n_articles=20,\n",
    "      return_type=\"both\",\n",
    "      strategy=\"news knowledge\" # looks for relevant news within the past 60 days\n",
    "  )\n",
    "\n",
    "  # you can also specify a time range for your historical search if you want to\n",
    "  # slice your search up periodically.\n",
    "  # now = datetime.datetime.now().timestamp()\n",
    "  # start = (datetime.datetime.now() - datetime.timedelta(days=100)).timestamp()\n",
    "  # historical_response = ask.news.search_news(\n",
    "  #     query=query,\n",
    "  #     n_articles=20,\n",
    "  #     return_type=\"both\",\n",
    "  #     historical=True,\n",
    "  #     start_timestamp=int(start),\n",
    "  #     end_timestamp=int(now)\n",
    "  # )\n",
    "\n",
    "  llm_context = hot_response.as_string + historical_response.as_string\n",
    "  formatted_articles = format_asknews_context(\n",
    "      hot_response.as_dicts, historical_response.as_dicts)\n",
    "  return llm_context, formatted_articles\n",
    "\n",
    "\n",
    "def format_asknews_context(hot_articles, historical_articles):\n",
    "  \"\"\"\n",
    "  Format the articles for posting to Metaculus.\n",
    "  \"\"\"\n",
    "\n",
    "  formatted_articles = \"Here are the relevant news articles:\\n\\n\"\n",
    "\n",
    "  if hot_articles:\n",
    "    hot_articles = [article.__dict__ for article in hot_articles]\n",
    "    hot_articles = sorted(\n",
    "        hot_articles, key=lambda x: x['pub_date'], reverse=True)\n",
    "\n",
    "    for article in hot_articles:\n",
    "        pub_date = article[\"pub_date\"].strftime(\"%B %d, %Y %I:%M %p\")\n",
    "        formatted_articles += f\"**{article['eng_title']}**\\n{article['summary']}\\nOriginal language: {article['language']}\\nPublish date: {pub_date}\\nSource:[{article['source_id']}]({article['article_url']})\\n\\n\"\n",
    "\n",
    "  if historical_articles:\n",
    "    historical_articles = [article.__dict__ for article in historical_articles]\n",
    "    historical_articles = sorted(\n",
    "        historical_articles, key=lambda x: x['pub_date'], reverse=True)\n",
    "\n",
    "    for article in historical_articles:\n",
    "        pub_date = article[\"pub_date\"].strftime(\"%B %d, %Y %I:%M %p\")\n",
    "        formatted_articles += f\"**{article['eng_title']}**\\n{article['summary']}\\nOriginal language: {article['language']}\\nPublish date: {pub_date}\\nSource:[{article['source_id']}]({article['article_url']})\\n\\n\"\n",
    "\n",
    "  if not hot_articles and not historical_articles:\n",
    "    formatted_articles += \"No articles were found.\\n\\n\"\n",
    "    return formatted_articles\n",
    "\n",
    "  formatted_articles += f\"*Generated by AI at [AskNews](https://asknews.app), check out the [API](https://docs.asknews.app) for more information*.\"\n",
    "\n",
    "  return formatted_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perplexity(LLM):\n",
    "    def message(self):\n",
    "        url = \"https://api.perplexity.ai/chat/completions\"\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"authorization\": f\"Bearer {config.PERPLEXITY_API_KEY}\",\n",
    "            \"content-type\": \"application/json\"  }\n",
    "        payload = {\"model\": config.PERPLEXITY_MODEL, \"messages\": self.messages }\n",
    "        response = requests.post(url=url, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD: Metaculus credentials"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "curl https://www.metaculus.com/proxy/openai/v1/chat/completions  \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -H \"Authorization: Token <your metaculus Token>\" \\\n",
    "  -d '{\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant.\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Who won the world series in 2020?\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Where was it played?\"\n",
    "      }\n",
    "    ]\n",
    "  }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatGPT(LLM):\n",
    "    def __init__(self, system_role):\n",
    "        super().__init__(system_role)\n",
    "        self.client = OpenAI(api_key=config.OPENAI_API_KEY)\n",
    "\n",
    "    def message(self):\n",
    "        chat_completion = self.client.chat.completions.create(\n",
    "            model=config.OPENAI_MODEL,\n",
    "            messages= self.messages)\n",
    "        return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test questions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "jul25 = [26638, 26639, 26640, 26641, 26642, 26643, 26644, 26645, 26646]\n",
    "\n",
    "ifps = {id: IFP(id) for id in jul25}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WUvm1tVmMkO"
   },
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, system_role, llm):\n",
    "        self.llm = llm(system_role)\n",
    "\n",
    "    def chat(self, prompt):\n",
    "        return self.llm.chat(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rate Analyzer(TBD: ChatGPT is better)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class RateAnalyzer(Agent):\n",
    "    def __init__(self, llm):\n",
    "        self.system_role = f\"\"\"\n",
    "A question about an event is formatted as |id|question|criteria|background|fineprint|.\n",
    "Today's date is {today}.\n",
    "You will report \n",
    "1. today's date, \n",
    "2. the end date of the question, \n",
    "3. the time in days D from today to end date, \n",
    "4. the daily rate of change R of the quantity,\n",
    "5. today's value V of the quantity,\n",
    "6. the change in value dV of the quantity = D * r,\n",
    "7. the final value of the quantity F = V + dV.  Give your best estimate.\n",
    "\"\"\"\n",
    "        super().__init__(self.system_role, llm)\n",
    "\n",
    "    def recherche(self, ifp):\n",
    "        prompt = f\"|{ifp.question_id}|{ifp.title}|{ifp.resolution_criteria}|{ifp.background}|{ifp.fine_print}|\"\n",
    "        self.R = self.chat(prompt)\n",
    "        ifp.rates = self.R\n",
    "        print(ifp.question_id, ifp.title)\n",
    "        print(self.R)\n",
    "\n",
    "    def analyze(self, ifps):\n",
    "        for ifp in tqdm(ifps):\n",
    "            self.recherche(ifps[ifp])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rates = RateAnalyzer(Perplexity)\n",
    "rates.analyze(ifps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Researcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Researcher(Agent):\n",
    "    def __init__(self, llm):\n",
    "        self.system_role = f\"\"\"\n",
    "You are an open source intelligence analyst.\n",
    "You summarize news related to questions about events.\n",
    "A question about an event is formatted as |id|question|criteria|background|fineprint|.\n",
    "You will find on the web and report any reliable information you can gather about the question.\n",
    "Do not make an assessment of probability.\n",
    "Do not repeat information provided to you already in the prompt.\"\"\"\n",
    "        super().__init__(self.system_role, llm)\n",
    "\n",
    "    def recherche(self, ifp):\n",
    "        prompt = f\"|{ifp.question_id}|{ifp.title}|{ifp.resolution_criteria}|{ifp.background}|{ifp.fine_print}|\"\n",
    "        self.R = self.chat(prompt)\n",
    "        ifp.news = self.R\n",
    "        print(ifp.question_id, ifp.title)\n",
    "        print(self.R)\n",
    "\n",
    "    def research(self, ifps):\n",
    "        for ifp in tqdm(ifps):\n",
    "            self.recherche(ifps[ifp])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "researcher = Researcher(ChatGPT)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "researcher.research(ifps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question relator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionRelator(Agent):\n",
    "    def __init__(self, llm):\n",
    "        self.system_role = f\"\"\"\n",
    "You are prompted with list of forecasting questions, each with an id and a title.\n",
    "Label each question with an underlying event.\n",
    "If the questions are for the same event, use the same name for the underlying event.\n",
    "Please return as separate lines formatted as |event|id|title|, do not add any other formatting.\n",
    "\"\"\"\n",
    "        super().__init__(self.system_role, llm)\n",
    "\n",
    "    def relate(self, ifps):\n",
    "        prompt = '\\n'.join([f\"{ifp.question_id}: {ifp.title}\" for ifp in ifps.values()])\n",
    "        KL = self.chat(prompt)\n",
    "        K1 = [x.split('|') for x in KL.split('\\n')]\n",
    "        K2 = [(int(id),event) for _,event,id,_,_ in K1]\n",
    "        for id,event in K2:\n",
    "            ifps[id].event = event\n",
    "            print(id, event)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "qr = QuestionRelator(ChatGPT)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "qr.relate(ifps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Superforecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Superforecaster(Agent):\n",
    "    def __init__(self, llm):\n",
    "        self.system_role = f\"\"\"\n",
    "You are a superforecaster.  \n",
    "You assign a probability to questions about events.\n",
    "Questions are given as separate groups of lines formatted as |FORECAST|event|id|question|news|criteria|background|fineprint|.\n",
    "Groups are separated by '^^^'.\n",
    "Questions which are about the same event should be assigned consistent probabilities.\n",
    "Reply to questions with |ASSESSMENT|id|ZZ|rationale| where ZZ is an integer probability from 1 to 99 and rationale is your reasoning for the forecast.\n",
    "Separate each question with '^^^'.\n",
    "Do not add any additional headings or group labels or other formatting.\n",
    "After your initial forecast you may receive feedback of form |CRITIC|id|feedback|.\n",
    "Reply to each feedback with |id|ZZ|rationale| where ZZ is an integer probability from 1 to 99 and \n",
    "and rationale is a revised assessment which may be adjusted from a prior assessment due the feedback unless the feedback is \"I concur\".\n",
    "\"\"\"\n",
    "        super().__init__(self.system_role, llm)\n",
    "\n",
    "    def forecast(self, ifps):\n",
    "        prompt = '^^^'.join([f\"FORECAST|{ifp.event}|{ifp.question_id}|{ifp.news}|{ifp.resolution_criteria}|{ifp.background}|{ifp.fine_print}|\" for ifp in ifps.values()])\n",
    "        self.F0 = self.chat(prompt)\n",
    "        self.F1 = [x.strip().replace('\\n', '') for x in self.F0.split('^^^')]\n",
    "        self.F2 = [x.split('|') for x in self.F1] \n",
    "        self.F3 = [[x for x in y if x] for y in self.F2]\n",
    "        self.F4 = [(int(id),int(forecast),rationale) for _, id, forecast, rationale in self.F3]\n",
    "        for id, forecast, rationale in self.F4:\n",
    "            ifps[id].forecast = forecast\n",
    "            ifps[id].rationale = rationale\n",
    "            print(id, forecast, rationale)\n",
    "\n",
    "    def reassess(self, ifp):\n",
    "        prompt = f\"|CRITIC|{ifp.question_id}|{ifp.feedback}|\"\n",
    "        self.R0 = self.chat(prompt)\n",
    "        id,fcst,rationale = [x for x in self.R0.strip().split('|') if x]\n",
    "        id = int(id)\n",
    "        fcst = int(fcst)\n",
    "        ifps[id].forecast = fcst\n",
    "        ifps[id].rationale = rationale\n",
    "        print(id, fcst, rationale)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sf = Superforecaster(ChatGPT)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sf.forecast(ifps)\n",
    "\n",
    "for ifp in ifps.values():\n",
    "    if ifp.feedback != 'I concur':\n",
    "        sf.reassess(ifp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic (Agent):\n",
    "    def __init__(self, llm):\n",
    "\n",
    "        self.system_role = f\"\"\"\n",
    "You a very smart and worldly person reviewing a superforecaster's assignment of probabilities to events.\n",
    "You will receive an event with probabilities given as |event|id|question|zz|rationale|news|criteria|background|fineprint|.\n",
    "zz is an integer probability from 1 to 99 and rationale is the student's logic for assigning probability of zz.\n",
    "You will reply with a line |id|feedback| where feedback is \"I concur\" if you see no problem with the rationale and zz otherwise presents possible problems with the rationale and zz.\n",
    "\"\"\"\n",
    "        super().__init__(self.system_role, llm)\n",
    "\n",
    "    def feedback(self, ifp):\n",
    "        prompt = f\"|{ifp.event}|{ifp.question_id}|{ifp.title}|{ifp.forecast}|{ifp.rationale}|{ifp.news}|{ifp.resolution_criteria}|{ifp.background}|{ifp.fine_print}|\"\n",
    "        self.fb = self.chat(prompt)\n",
    "        self.fb1 = self.fb.split('|')\n",
    "        self.fb2 = [x for x in self.fb1 if x]\n",
    "        try:\n",
    "            id,feedback = self.fb2\n",
    "            ifps[int(id)].feedback = feedback\n",
    "            print(id, feedback)\n",
    "        except:\n",
    "            print('problem', self.fb2)\n",
    "            ifps[int(id)].feedback = 'I concur'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "categories = {\"Market Price\": \"The current or future prices or comparative price / value of goods, services, commodities, stocks, treasuries, indices, and other traded financial products. This excludes products which aren't traded and subject to supply and demand.\",\n",
    "                \"Macroeconomics\": \"A quantifiable measure with historical values being above, below, or between values. This includes all-time records, record lows, record highs, or simply exceeding a value at a specified time.\",\n",
    "                \"Epidemic\": \"The rate of spread of a disease\",\n",
    "                \"Disease\": \"A new outbreak of an old or new disease\",\n",
    "                \"Medical Device\": \"Invention or distribution of a new medical device\",\n",
    "                \"Drug Discovery\": \"Invention of a new drug for a specific medical condition\",\n",
    "                \"Civil Unrest\": \"Riots and protests\",\n",
    "                \"Crime\": \"Crime statistics\",\n",
    "                \"Elections\": \"Elections\",\n",
    "                \"Leadership change\": \"Leadership change but not from an election\",\n",
    "                \"Sports\": \"Sporting event outcomes and sport statistics\"}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dfc = pd.DataFrame(categories.items())\n",
    "text = \"\"\n",
    "for cat in categories:\n",
    "    descr = categories[cat]\n",
    "    text += f\"* {cat}: {descr}\\n\"\n",
    "dfc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "critic = Critic(Perplexity)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for ifp in ifps.values():\n",
    "    critic.feedback(ifp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add an agent to summarize the back and forth between critic and forecaster into a single cogent rationale that incorporates all that was discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting process"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ifps = {id: IFP(id) for id in jul25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecasting(ifps):\n",
    "    max_tries = 4\n",
    "    \n",
    "    analyst = Researcher(ChatGPT)\n",
    "    analyst.research(ifps)\n",
    "    \n",
    "    qr = QuestionRelator(ChatGPT)\n",
    "    qr.relate(ifps)\n",
    "    \n",
    "    sf = Superforecaster(ChatGPT)\n",
    "    sf.forecast(ifps)\n",
    "    \n",
    "    for ifp in ifps.values():\n",
    "        print(\"Refining\", ifp.question_id)\n",
    "        ifp.feedback = ''\n",
    "        critic = Critic(Perplexity)\n",
    "        for i in range(max_tries):\n",
    "            print(\"Pass\", i, \"of\", max_tries, \"on\", ifp.question_id)\n",
    "            if 'I concur' in ifp.feedback:\n",
    "                break\n",
    "            critic.feedback(ifp)\n",
    "            if 'I concur' in ifp.feedback:\n",
    "                break\n",
    "            sf.reassess(ifp)\n",
    "        print(\"===============================================\")\n",
    "\n",
    "    for ifp in ifps.values():\n",
    "        print(ifp.question_id, ifp.title)\n",
    "        print(\"Forecast\", ifp.forecast)\n",
    "        print(\"Rationale\", ifp.rationale, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload(ifp):\n",
    "    post_question_prediction(ifp.question_id, ifp.forecast)\n",
    "    post_question_comment(ifp.question_id, ifp.rationale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uploads(ifps):\n",
    "    for ifp in ifps.values():\n",
    "        upload(ifp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get IFP ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifps = list_questions()['results']\n",
    "today_ids = list(sorted([x['id'] for x in ifps]))\n",
    "# today_ids = [25876, 25877, 25875, 25873, 25871, 25878, 25874, 25872] # 08JUL24\n",
    "# today_ids = [26006, 25936, 25935, 25934, 25933, 26004, 26005] # 09JUL24\n",
    "# today_ids = [25955, 25956, 25957, 25960, 25959, 25954, 25953, 25952, 25958] # 10JUL24\n",
    "# today_ids = [26019, 26018, 26017, 26020, 26022, 26021, 26023, 26024] # 11JUL24\n",
    "# today_ids = [26095, 26096, 26097, 26098, 26099, 26100, 26101, 26102] # 12JUL24\n",
    "# today_ids = [26133, 26134, 26138, 26139, 26140, 26157, 26158, 26159] # 15JUL24\n",
    "# today_ids = [26189, 26190, 26191, 26192, 26193, 26194, 26195, 26196] # 16JUL24\n",
    "# today_ids = [26210, 26211, 26212, 26213, 26214, 26215, 26216] # 17JUL24\n",
    "# today_ids = [26232, 26233, 26234, 26235, 26236] # 18JUL24\n",
    "# today_ids = [26302, 26303, 26304, 26305, 26306, 26307] # 19JUL24\n",
    "# today_ids = [26387, 26388, 26389, 26390, 26391, 26392] # 22JUL24\n",
    "# today_ids = [26404, 26405, 26406, 26407, 26408] # 23JUL24\n",
    "# today_ids = [26550, 26551, 26552, 26553, 26554, 26555] # 24JUL24\n",
    "# today_ids = [26568, 26569, 26570, 26571, 26572, 26573, 26574, 26575, 26576, 26577] # 25JUL24\n",
    "# today_ids = [26638, 26639, 26640, 26641, 26642, 26643, 26644, 26645, 26646] # 26JUL24\n",
    "# today_ids = [26665, 26666, 26667, 26668, 26669, 26670, 26671, 26683] # 29JUL24\n",
    "# today_ids = [26700, 26701, 26702, 26703, 26704, 26705, 26706] # 30JUL24\n",
    "# today_ids = [26816, 26817, 26818, 26819, 26820, 26821, 26844] # 31JUL24\n",
    "# today_ids = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "today_ids = [26771, 26772, 26773, 26774, 26775, 26776, 26777, 26778, 26779, 26780, 26781]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifps = {id: IFP(id) for id in today_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|████                                        | 1/11 [00:01<00:18,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26771 Will Fabiano Caruana win the 2024 Grand Chess Tour?\n",
      "As of now, the official standings on the Grand Chess Tour website list Fabiano Caruana leading with 22.25 points, with two events still to be held: the 2024 Saint Louis Rapid & Blitz and the 2024 Sinquefield Cup. Caruana's performance in these remaining tournaments will determine if he wins the Grand Chess Tour. You may follow real-time updates on the official Grand Chess Tour site for the most accurate and up-to-date information on the standings and performances.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████                                    | 2/11 [00:08<00:43,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26772 Will Alireza Firouzja win the 2024 Grand Chess Tour?\n",
      "As of now, according to the official standings on the Grand Chess Tour website, Alireza Firouzja is in second place with 17.58 points, behind Fabiano Caruana who leads with 22.25 points. There are still two events remaining: the 2024 Saint Louis Rapid & Blitz and the 2024 Sinquefield Cup. Firouzja's performance in these upcoming tournaments will determine if he can overtake Caruana and win the Grand Chess Tour. You should regularly check the Grand Chess Tour site and other credible sources for real-time updates on standings and results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████                                | 3/11 [00:10<00:28,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26773 Will Praggnanandhaa Rameshbabu win the 2024 Grand Chess Tour?\n",
      "As of now, the official standings on the Grand Chess Tour website show Praggnanandhaa Rameshbabu in third place with 16.25 points, behind Fabiano Caruana and Alireza Firouzja. The two remaining events in the tour are the 2024 Saint Louis Rapid & Blitz and the 2024 Sinquefield Cup, which will determine the final standings.\n",
      "\n",
      "Praggnanandhaa's performance in these upcoming tournaments will be critical in determining whether he can win the 2024 Grand Chess Tour. For the latest updates and accurate information, keep an eye on the Grand Chess Tour's official website and other credible sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|████████████████                            | 4/11 [00:13<00:23,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26774 Will Gukesh Dommaraju win the 2024 Grand Chess Tour?\n",
      "As of now, Gukesh Dommaraju is not in the top three of the current standings for the 2024 Grand Chess Tour. The top three players are Fabiano Caruana with 22.25 points, Alireza Firouzja with 17.58 points, and Praggnanandhaa Rameshbabu with 16.25 points.\n",
      "\n",
      "However, with two tournaments remaining—the 2024 Saint Louis Rapid & Blitz and the 2024 Sinquefield Cup—Gukesh still has a chance to improve his standing and potentially win the Tour depending on his performance in these events. For the latest updates and accurate information on the standings and tournament results, keep an eye on the Grand Chess Tour's official website and other credible sources.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████████████                        | 5/11 [00:18<00:23,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26775 Will someone other than Fabiano Caruana, Alireza Firouzja, Praggnanandhaa Rameshbabu, or Gukesh Dommaraju win the 2024 Grand Chess Tour?\n",
      "As of now, the top three positions in the current standings for the 2024 Grand Chess Tour are held by Fabiano Caruana with 22.25 points, Alireza Firouzja with 17.58 points, and Praggnanandhaa Rameshbabu with 16.25 points. Gukesh Dommaraju is also mentioned as a contender lower in the rankings.\n",
      "\n",
      "With two tournaments—a quicker time control event (the 2024 Saint Louis Rapid & Blitz) and a longer, classical time control event (the 2024 Sinquefield Cup)—still to be held, other players in the tour still have a chance to climb up the standings. However, significant changes in performance would be required for someone outside these four mentioned players to win the Tour.\n",
      "\n",
      "To determine whether someone other than Fabiano Caruana, Alireza Firouzja, Praggnanandhaa Rameshbabu, or Gukesh Dommaraju wins the 2024 Grand Chess Tour, you should monitor the results and standings on the Grand Chess Tour's official website and other credible chess news sources for real-time updates.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████████                    | 6/11 [00:22<00:19,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26776 Will the Seattle-Tacoma-Bellevue WA metro area experience exactly 1 day with an Air Quality Index value above 150 in the 3rd quarter of 2024?\n",
      "As of the given information up to July 29, 2024, the Seattle-Tacoma-Bellevue WA metro area has already experienced one day with an AQI above 150 in the third quarter of 2024, specifically on July 5, 2024, when the AQI was reported to be 166.\n",
      "\n",
      "To determine if the metro area will experience exactly one day with an AQI value above 150 in the third quarter of 2024, you will need to monitor the EPA’s outdoor air quality data tool for the complete period from July 1, 2024, to September 30, 2024. The final data will be available and should be accessed on or after October 2, 2024.\n",
      "\n",
      "For accessing the data, ensure the following selections:\n",
      "\n",
      "- Select Pollutant: All AQI Pollutants\n",
      "- Year: 2024\n",
      "- Geographic Area: Seattle-Tacoma-Bellevue WA\n",
      "- Monitor Site: All Sites (Highest Daily AQI)\n",
      "\n",
      "Each day with an AQI above 150 will be counted, including the categories Unhealthy, Very Unhealthy, and Hazardous.\n",
      "\n",
      "Given the historical trend and the information available, continuous monitoring is required to see if any additional days in the specified period will have an AQI above 150.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████████████                | 7/11 [00:27<00:16,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26777 Will the Seattle-Tacoma-Bellevue WA metro area experience 2 to 5 days with an Air Quality Index value above 150 in the 3rd quarter of 2024?\n",
      "As of the provided information up to July 29, 2024, there has been one day in the third quarter of 2024 with an AQI above 150 in the Seattle-Tacoma-Bellevue WA metro area, specifically on July 5, 2024, with an AQI of 166.\n",
      "\n",
      "To determine whether the metro area will experience 2 to 5 days with an AQI value above 150 in the third quarter of 2024, you will need to monitor the EPA’s outdoor air quality data tool for the entire period from July 1, 2024, to September 30, 2024. The final data can be reviewed on or after October 2, 2024.\n",
      "\n",
      "For accessing the data, ensure the following selections:\n",
      "\n",
      "- **Select Pollutant:** All AQI Pollutants\n",
      "- **Year:** 2024\n",
      "- **Geographic Area:** Seattle-Tacoma-Bellevue WA\n",
      "- **Monitor Site:** All Sites (Highest Daily AQI)\n",
      "\n",
      "Days with an AQI above 150 will be counted, including the categories Unhealthy, Very Unhealthy, and Hazardous.\n",
      "\n",
      "Monitoring this data through the EPA’s tool and noting additional days with AQI above 150 during the specified period is necessary to determine if the Seattle-Tacoma-Bellevue WA metro area will have 2 to 5 days within that range in Q3 2024. As of the latest update, there have been only one such day. Further monitoring required to see if it reaches the 2 to 5 days threshold.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████████            | 8/11 [00:32<00:12,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26778 Will the Seattle-Tacoma-Bellevue WA metro area experience 6 to 10 days with an Air Quality Index value above 150 in the 3rd quarter of 2024?\n",
      "As of the information provided up to July 29, 2024, the Seattle-Tacoma-Bellevue WA metro area has experienced one day with an AQI above 150 in the third quarter of 2024, specifically on July 5, 2024, with an AQI of 166.\n",
      "\n",
      "To determine whether the metro area will experience 6 to 10 days with an AQI value above 150 in the third quarter of 2024, you will need to refer to the EPA’s outdoor air quality data tool for the period from July 1, 2024, to September 30, 2024. The final data will become available and should be reviewed on or after October 2, 2024.\n",
      "\n",
      "For accessing the data, use the following selections:\n",
      "- **Select Pollutant:** All AQI Pollutants\n",
      "- **Year:** 2024\n",
      "- **Geographic Area:** Seattle-Tacoma-Bellevue WA\n",
      "- **Monitor Site:** All Sites (Highest Daily AQI)\n",
      "\n",
      "Days with an AQI above 150 will be counted, including categories such as Unhealthy, Very Unhealthy, and Hazardous.\n",
      "\n",
      "You can continue monitoring the EPA tool to see if further days with AQI values above 150 occur within the specified period. Currently, there has been only one such day, and additional monitoring is required to determine if the total will fall within the 6 to 10 days range.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████████████████████████████████        | 9/11 [00:36<00:08,  4.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26779 Will the Seattle-Tacoma-Bellevue WA metro area experience 11 or more days with an Air Quality Index value above 150 in the 3rd quarter of 2024?\n",
      "As of the information provided up to July 29, 2024, the Seattle-Tacoma-Bellevue WA metro area has experienced one day with an AQI above 150 in the third quarter of 2024, specifically on July 5, 2024, with an AQI of 166.\n",
      "\n",
      "To determine whether the metro area will experience 11 or more days with an AQI value above 150 in the third quarter of 2024, you will need to refer to the EPA’s outdoor air quality data tool for the entire period from July 1, 2024, to September 30, 2024. The final data can be reviewed on or after October 2, 2024.\n",
      "\n",
      "For accessing the data, use the following steps:\n",
      "\n",
      "- **Select Pollutant:** All AQI Pollutants\n",
      "- **Year:** 2024\n",
      "- **Geographic Area:** Seattle-Tacoma-Bellevue WA\n",
      "- **Monitor Site:** All Sites (Highest Daily AQI)\n",
      "\n",
      "Days with an AQI above 150 will be counted, including categories such as Unhealthy, Very Unhealthy, and Hazardous.\n",
      "\n",
      "At present, with only one day recorded above 150 AQI, close monitoring of air quality data is necessary to determine if the total will reach or exceed 11 days within the specified time frame. Further data collection will reveal if more days with an AQI above 150 occur.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|███████████████████████████████████████    | 10/11 [00:39<00:04,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26780 Will Bitcoin reach a new all-time high before October 1, 2024?\n",
      "To determine if Bitcoin reaches a new all-time high (ATH) before October 1, 2024, you will need to regularly monitor the price listed on CoinMarketCap. The current ATH price as per CoinMarketCap is $73,750.07, recorded on March 14, 2024. The new ATH must exceed this price and occur between July 30 and October 1, 2024. \n",
      "\n",
      "**Key Points to Monitor:**\n",
      "- **Current ATH:** $73,750.07 (as of March 14, 2024).\n",
      "- **Date of potential new ATH:** Between July 30 and October 1, 2024.\n",
      "- **Price Source:** CoinMarketCap (or an alternative like CoinGecko if data is ambiguous or unavailable on the primary site).\n",
      "\n",
      "### Monitoring Steps:\n",
      "1. Regularly check the Bitcoin price on [CoinMarketCap](https://coinmarketcap.com/currencies/bitcoin/).\n",
      "2. Compare the current price with the existing ATH of $73,750.07.\n",
      "3. Record any new ATHs that occur between July 30 and October 1, 2024.\n",
      "\n",
      "If Bitcoin’s price reaches a new ATH above $73,750.07 in the specified period, the question will resolve as **Yes**. If not, it will resolve as **No**.\n",
      "\n",
      "Keep a close watch on cryptocurrency news and market movements as they can significantly impact the price of Bitcoin.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 11/11 [00:45<00:00,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26781 Will William Ruto cease to be President of Kenya before October 1, 2024?\n",
      "As of now, William Ruto remains the President of Kenya despite the serious political unrest and significant actions such as the dismissal and partial reinstatement of his cabinet, the resignation of the police chief, and ongoing nationwide protests calling for his resignation.\n",
      "\n",
      "### Key Points to Monitor:\n",
      "1. **Current Status:** William Ruto is still the President of Kenya.\n",
      "2. **Criteria for Resolution as Yes:**\n",
      "    - Resignation\n",
      "    - Impeachment\n",
      "    - Losing an election\n",
      "    - Removal from office via a coup\n",
      "    - Any other reason leading to ceasing to be President before October 1, 2024\n",
      "3. **Compliance with Fine Print:** If Ruto is temporarily replaced but resumes duties within 30 days, it does not count. If he resumes duties after more than 30 days (completed before October 1, 2024), it resolves as Yes.\n",
      "4. **Credible Sources:** Information from major news outlets and official listings like the [UN Heads of State list](https://www.un.org/dgacm/en/content/protocol/hshgnfa).\n",
      "\n",
      "### Current Context:\n",
      "- **Protests and Cabinet Changes:** Protests were sparked by proposed tax hikes and led to nationwide unrest. In response, Ruto dismissed and partially reinstated his cabinet, even appointing some opposition members.\n",
      "- **Police Chief's Resignation:** The resignation of Inspector General Japhet Koome amid accusations of excessive force on protestors.\n",
      "- **Public Sentiment:** There are ongoing calls for Ruto's resignation due to various issues, including corruption, unemployment, and broken promises.\n",
      "\n",
      "To determine the final resolution:\n",
      "- **Regular Monitoring:** Keep an eye on updates from reliable news sources about any changes in the presidency status of William Ruto.\n",
      "- **Verification on October 2, 2024, or shortly after:** Check credible sources and the UN Heads of State list to confirm if Ruto is still the President of Kenya.\n",
      "\n",
      "As of the latest updates, no credible sources indicate that Ruto has ceased to be the President, but the situation is volatile and should be closely observed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26771 2024 Grand Chess Tour\n",
      "26772 2024 Grand Chess Tour\n",
      "26773 2024 Grand Chess Tour\n",
      "26774 2024 Grand Chess Tour\n",
      "26775 2024 Grand Chess Tour\n",
      "26776 Seattle-Tacoma-Bellevue WA Air Quality\n",
      "26777 Seattle-Tacoma-Bellevue WA Air Quality\n",
      "26778 Seattle-Tacoma-Bellevue WA Air Quality\n",
      "26779 Seattle-Tacoma-Bellevue WA Air Quality\n",
      "26780 Bitcoin Price\n",
      "26781 William Ruto Presidency\n",
      "26771 60 Fabiano Caruana holds a significant lead and has shown strong performance in the tour so far. While there are still two tournaments left, his point advantage makes it relatively more likely for him to secure the overall win despite potential strong performances by rivals.\n",
      "26772 30 Alireza Firouzja is currently behind Caruana and while he possesses the skill to potentially outperform Caruana in the remaining tournaments, the point gap suggests it is less likely.\n",
      "26773 20 Praggnanandhaa Rameshbabu is further behind in the standings compared to Caruana and Firouzja, making it less probable for him to win the overall tour unless he performs exceptionally well in both remaining events while others do not.\n",
      "26774 10 Gukesh Dommaraju is currently outside the top three, implying it is unlikely for him to make up the deficit and win the tour given the remaining competitions and the current standings.\n",
      "26775 5 With the current standings and the strong performance by the top players, it is highly improbable for someone outside of Caruana, Firouzja, Praggnanandhaa, or Gukesh to win the tour.\n",
      "26776 15 Given the historical data and the fact that there has already been one day with an AQI above 150, it is relatively rare for there to be only one such day, but it remains possible.\n",
      "26777 40 Based on the historical trend of wildfires contributing to poor air quality, having 2 to 5 days with AQI above 150 in the given period is moderately likely.\n",
      "26778 25 While it is not extremely common to have 6 to 10 days of AQI above 150, the potential for prolonged wildfires makes this scenario somewhat plausible.\n",
      "26779 10 With only one day recorded so far, and considering historical data, it is less likely but possible to have 11 or more days with AQI above 150 unless there is a severe and sustained wildfire impact.\n",
      "26780 20 Despite a recent high of $69,000, Bitcoin reaching a new all-time high above $73,750.07 by October 1, 2024, is less probable given market volatility and historical patterns.\n",
      "26781 30 While the situation is volatile and there have been significant protests, historical context suggests a moderate likelihood of William Ruto ceasing to be President due to the resilience historically seen in such situations.\n",
      "Refining 26771\n",
      "Pass 0 of 4 on 26771\n",
      "26771 I concur\n",
      "===============================================\n",
      "Refining 26772\n",
      "Pass 0 of 4 on 26772\n",
      "26772 The probability of 30 seems low considering Firouzja's current standing and his past performance in similar tournaments. While Caruana leads, Firouzja has shown his ability to perform well in various formats, including rapid and blitz chess. Given that there are still two events remaining, Firouzja's chances of overtaking Caruana are higher than the assigned probability suggests.\n",
      "26772 40 Given Firouzja's strong performance history in various formats and the remaining two tournaments, it's reasonable to increase the likelihood of him potentially overtaking Caruana.\n",
      "Pass 1 of 4 on 26772\n",
      "26772 I concur.\n",
      "===============================================\n",
      "Refining 26773\n",
      "Pass 0 of 4 on 26773\n",
      "26773 I concur\n",
      "===============================================\n",
      "Refining 26774\n",
      "Pass 0 of 4 on 26774\n",
      "26774 The rationale seems sound, but the probability of 10 might be too low. Gukesh still has a chance to improve his standing and potentially win the Tour depending on his performance in the remaining events. Considering the current standings and the tournaments left to play, a more appropriate probability might be around 20-30.\n",
      "26774 20 Gukesh has a chance to improve his standing with strong performances in the remaining events. Given this potential, a higher probability is warranted.\n",
      "Pass 1 of 4 on 26774\n",
      "26774 I concur. The rationale is sound, and the probability of 20 is reasonable given Gukesh's potential to improve his standing with strong performances in the remaining events.\n",
      "===============================================\n",
      "Refining 26775\n",
      "Pass 0 of 4 on 26775\n",
      "26775 I concur\n",
      "===============================================\n",
      "Refining 26776\n",
      "Pass 0 of 4 on 26776\n",
      "26776 The assigned probability of 15 seems low given the historical data. Seattle has experienced multiple days with AQI above 150 in recent years, especially during the late summer and fall due to wildfires. The fact that there has already been one such day in the third quarter of 2024 suggests that additional days with high AQI are possible.\n",
      "26776 30 Given the historical trend of multiple days with AQI above 150 due to wildfires, along with the fact that one such day has already occurred, a higher probability is appropriate.\n",
      "Pass 1 of 4 on 26776\n",
      "26776 The assigned probability of 30 seems more reasonable given the historical trend of multiple days with AQI above 150 due to wildfires, along with the fact that one such day has already occurred.\n",
      "26776 30 Given the historical trend of multiple days with AQI above 150 due to wildfires, along with the fact that one such day has already occurred, a probability of 30 is appropriate.\n",
      "Pass 2 of 4 on 26776\n",
      "26776 I concur.\n",
      "===============================================\n",
      "Refining 26777\n",
      "Pass 0 of 4 on 26777\n",
      "26777 The probability of 40 seems reasonable given the historical trend of wildfires contributing to poor air quality in the Seattle-Tacoma-Bellevue WA metro area. The rationale is well-supported by the provided information and the context of the question. I concur.\n",
      "===============================================\n",
      "Refining 26778\n",
      "Pass 0 of 4 on 26778\n",
      "26778 The rationale seems plausible, but the probability of 25% might be too low. Historical data suggests that the Seattle-Tacoma-Bellevue WA metro area has experienced multiple days with AQI above 150 in the past, and the potential for prolonged wildfires makes this scenario more likely.\n",
      "26778 35 Considering the historical data and the potential for prolonged wildfires leading to multiple days with AQI above 150, an increased probability is justified.\n",
      "Pass 1 of 4 on 26778\n",
      "26778 The rationale seems plausible, but the probability of 35% might be too low. Historical data suggests that the Seattle-Tacoma-Bellevue WA metro area has experienced multiple days with AQI above 150 in the past, and the potential for prolonged wildfires makes this scenario more likely.\n",
      "26778 45 Considering the historical data and the potential for prolonged wildfires, a further increased probability better reflects the risk of having 6 to 10 days with AQI above 150.\n",
      "Pass 2 of 4 on 26778\n",
      "26778 I concur.\n",
      "===============================================\n",
      "Refining 26779\n",
      "Pass 0 of 4 on 26779\n",
      "26779 I concur\n",
      "===============================================\n",
      "Refining 26780\n",
      "Pass 0 of 4 on 26780\n",
      "26780 I concur\n",
      "===============================================\n",
      "Refining 26781\n",
      "Pass 0 of 4 on 26781\n",
      "26781 I concur\n",
      "===============================================\n",
      "26771 Will Fabiano Caruana win the 2024 Grand Chess Tour?\n",
      "Forecast 60\n",
      "Rationale Fabiano Caruana holds a significant lead and has shown strong performance in the tour so far. While there are still two tournaments left, his point advantage makes it relatively more likely for him to secure the overall win despite potential strong performances by rivals. \n",
      "\n",
      "26772 Will Alireza Firouzja win the 2024 Grand Chess Tour?\n",
      "Forecast 40\n",
      "Rationale Given Firouzja's strong performance history in various formats and the remaining two tournaments, it's reasonable to increase the likelihood of him potentially overtaking Caruana. \n",
      "\n",
      "26773 Will Praggnanandhaa Rameshbabu win the 2024 Grand Chess Tour?\n",
      "Forecast 20\n",
      "Rationale Praggnanandhaa Rameshbabu is further behind in the standings compared to Caruana and Firouzja, making it less probable for him to win the overall tour unless he performs exceptionally well in both remaining events while others do not. \n",
      "\n",
      "26774 Will Gukesh Dommaraju win the 2024 Grand Chess Tour?\n",
      "Forecast 20\n",
      "Rationale Gukesh has a chance to improve his standing with strong performances in the remaining events. Given this potential, a higher probability is warranted. \n",
      "\n",
      "26775 Will someone other than Fabiano Caruana, Alireza Firouzja, Praggnanandhaa Rameshbabu, or Gukesh Dommaraju win the 2024 Grand Chess Tour?\n",
      "Forecast 5\n",
      "Rationale With the current standings and the strong performance by the top players, it is highly improbable for someone outside of Caruana, Firouzja, Praggnanandhaa, or Gukesh to win the tour. \n",
      "\n",
      "26776 Will the Seattle-Tacoma-Bellevue WA metro area experience exactly 1 day with an Air Quality Index value above 150 in the 3rd quarter of 2024?\n",
      "Forecast 30\n",
      "Rationale Given the historical trend of multiple days with AQI above 150 due to wildfires, along with the fact that one such day has already occurred, a probability of 30 is appropriate. \n",
      "\n",
      "26777 Will the Seattle-Tacoma-Bellevue WA metro area experience 2 to 5 days with an Air Quality Index value above 150 in the 3rd quarter of 2024?\n",
      "Forecast 40\n",
      "Rationale Based on the historical trend of wildfires contributing to poor air quality, having 2 to 5 days with AQI above 150 in the given period is moderately likely. \n",
      "\n",
      "26778 Will the Seattle-Tacoma-Bellevue WA metro area experience 6 to 10 days with an Air Quality Index value above 150 in the 3rd quarter of 2024?\n",
      "Forecast 45\n",
      "Rationale Considering the historical data and the potential for prolonged wildfires, a further increased probability better reflects the risk of having 6 to 10 days with AQI above 150. \n",
      "\n",
      "26779 Will the Seattle-Tacoma-Bellevue WA metro area experience 11 or more days with an Air Quality Index value above 150 in the 3rd quarter of 2024?\n",
      "Forecast 10\n",
      "Rationale With only one day recorded so far, and considering historical data, it is less likely but possible to have 11 or more days with AQI above 150 unless there is a severe and sustained wildfire impact. \n",
      "\n",
      "26780 Will Bitcoin reach a new all-time high before October 1, 2024?\n",
      "Forecast 20\n",
      "Rationale Despite a recent high of $69,000, Bitcoin reaching a new all-time high above $73,750.07 by October 1, 2024, is less probable given market volatility and historical patterns. \n",
      "\n",
      "26781 Will William Ruto cease to be President of Kenya before October 1, 2024?\n",
      "Forecast 30\n",
      "Rationale While the situation is volatile and there have been significant protests, historical context suggests a moderate likelihood of William Ruto ceasing to be President due to the resilience historically seen in such situations. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "forecasting(ifps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction posted for  26771\n",
      "Comment posted for  26771\n",
      "Prediction posted for  26772\n",
      "Comment posted for  26772\n",
      "Prediction posted for  26773\n",
      "Comment posted for  26773\n",
      "Prediction posted for  26774\n",
      "Comment posted for  26774\n",
      "Prediction posted for  26775\n",
      "Comment posted for  26775\n",
      "Prediction posted for  26776\n",
      "Comment posted for  26776\n",
      "Prediction posted for  26777\n",
      "Comment posted for  26777\n",
      "Prediction posted for  26778\n",
      "Comment posted for  26778\n",
      "Prediction posted for  26779\n",
      "Comment posted for  26779\n",
      "Prediction posted for  26780\n",
      "Comment posted for  26780\n",
      "Prediction posted for  26781\n",
      "Comment posted for  26781\n"
     ]
    }
   ],
   "source": [
    "uploads(ifps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(today_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
