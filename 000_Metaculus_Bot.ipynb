{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 000 Forecasting Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from https://colab.research.google.com/drive/1_Il5h2Ed4zFa6Z3bROVCE68LZcSi4wHX?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run this notebook as is, you'll need to enter a few API keys (use the key icon on the left to input them):\n",
    "\n",
    "- `METACULUS_TOKEN`: you can find your Metaculus token under your bot's user settings page: https://www.metaculus.com/accounts/settings/, or on the bot registration page where you created the account: https://www.metaculus.com/aib/\n",
    "- `OPENAPI_API_KEY`: get one from OpenAIs page: https://platform.openai.com/settings/profile?tab=api-keys\n",
    "- `PERPLEXITY_API_KEY` - used to search up-to-date information about the question. Get one from https://www.perplexity.ai/settings/api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "tokens = OmegaConf.create(\"\"\"\n",
    "METACULUS_TOKEN: xx\n",
    "OPENAI_API_KEY: yy\n",
    "OPENAI_MODEL: gpt-4o\n",
    "PERPLEXITY_API_KEY: zz\n",
    "PERPLEXITY_MODEL: llama-3-sonar-large-32k-online\"\"\")\n",
    "\n",
    "token_fn = \"tokens.yaml\"\n",
    "# OmegaConf.save(config=tokens, f=token_fn)\n",
    "config = OmegaConf.load(token_fn)\n",
    "\n",
    "def pr(tokens):\n",
    "    print(OmegaConf.to_yaml(config))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pr(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDukuXArbgdm"
   },
   "source": [
    "## LLM and Metaculus Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDukuXArbgdm"
   },
   "source": [
    "This section sets up some simple helper code you can use to get data about forecasting questions and to submit a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HifodCwcGU0j"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HifodCwcGU0j"
   },
   "outputs": [],
   "source": [
    "AUTH_HEADERS = {\"headers\": {\"Authorization\": f\"Token {config.METACULUS_TOKEN}\"}}\n",
    "API_BASE_URL = \"https://www.metaculus.com/api2\"\n",
    "WARMUP_TOURNAMENT_ID = 3349\n",
    "SUBMIT_PREDICTION = True\n",
    "\n",
    "def find_number_before_percent(s):\n",
    "    # Use a regular expression to find all numbers followed by a '%'\n",
    "    matches = re.findall(r'(\\d+)%', s)\n",
    "    if matches:\n",
    "        # Return the last number found before a '%'\n",
    "        return int(matches[-1])\n",
    "    else:\n",
    "        # Return None if no number found\n",
    "        return None\n",
    "\n",
    "def post_question_comment(question_id, comment_text):\n",
    "    \"\"\"\n",
    "    Post a comment on the question page as the bot user.\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.post(\n",
    "        f\"{API_BASE_URL}/comments/\",\n",
    "        json={\n",
    "            \"comment_text\": comment_text,\n",
    "            \"submit_type\": \"N\",\n",
    "            \"include_latest_prediction\": True,\n",
    "            \"question\": question_id,\n",
    "        },\n",
    "        **AUTH_HEADERS,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    print(\"Comment posted for \", question_id)\n",
    "\n",
    "def post_question_prediction(question_id, prediction_percentage):\n",
    "    \"\"\"\n",
    "    Post a prediction value (between 1 and 100) on the question.\n",
    "    \"\"\"\n",
    "    url = f\"{API_BASE_URL}/questions/{question_id}/predict/\"\n",
    "    response = requests.post(\n",
    "        url,\n",
    "        json={\"prediction\": float(prediction_percentage) / 100},\n",
    "        **AUTH_HEADERS,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    print(\"Prediction posted for \", question_id)\n",
    "\n",
    "\n",
    "def get_question_details(question_id):\n",
    "    \"\"\"\n",
    "    Get all details about a specific question.\n",
    "    \"\"\"\n",
    "    url = f\"{API_BASE_URL}/questions/{question_id}/\"\n",
    "    response = requests.get(\n",
    "        url,\n",
    "        **AUTH_HEADERS,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    return json.loads(response.content)\n",
    "\n",
    "def list_questions(tournament_id=WARMUP_TOURNAMENT_ID, offset=0, count=1000):\n",
    "    \"\"\"\n",
    "    List (all details) {count} questions from the {tournament_id}\n",
    "    \"\"\"\n",
    "    url_qparams = {\n",
    "        \"limit\": count,\n",
    "        \"offset\": offset,\n",
    "        \"has_group\": \"false\",\n",
    "        \"order_by\": \"-activity\",\n",
    "        \"forecast_type\": \"binary\",\n",
    "        \"project\": tournament_id,\n",
    "        \"status\": \"open\",\n",
    "        \"type\": \"forecast\",\n",
    "        \"include_description\": \"true\",\n",
    "    }\n",
    "    url = f\"{API_BASE_URL}/questions/\"\n",
    "    response = requests.get(url, **AUTH_HEADERS, params=url_qparams)\n",
    "    response.raise_for_status()\n",
    "    data = json.loads(response.content)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(PERPLEXITY_PROMPT1, query):\n",
    "    payload = {\n",
    "    \"model\": config.PERPLEXITY_MODEL,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": PERPLEXITY_PROMPT1,\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ],\n",
    "    }\n",
    "    url = \"https://api.perplexity.ai/chat/completions\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"authorization\": f\"Bearer {config.PERPLEXITY_API_KEY}\",\n",
    "        \"content-type\": \"application/json\",\n",
    "    }\n",
    "    response = requests.post(url=url, json=payload, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    research1 = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return research1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai(client, OPENAI_PROMPT1):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model=config.OPENAI_MODEL,\n",
    "        messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": OPENAI_PROMPT1\n",
    "        }\n",
    "        ]\n",
    "    )\n",
    "    forecast1 = chat_completion.choices[0].message.content\n",
    "    return forecast1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WUvm1tVmMkO"
   },
   "source": [
    "## Forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Forecaster:\n",
    "\n",
    "    def __init__(self, question_id):\n",
    "        self.question_id = question_id\n",
    "        self.question_details = get_question_details(self.question_id)\n",
    "        self.client = OpenAI(api_key=config.OPENAI_API_KEY)\n",
    "        \n",
    "    def predict(self):\n",
    "        self.today = datetime.datetime.now().strftime(\"%Y-%m-%d\")   \n",
    "        self.title = self.question_details[\"title\"]\n",
    "        self.resolution_criteria = self.question_details[\"resolution_criteria\"]\n",
    "        self.background = self.question_details[\"description\"]\n",
    "        self.fine_print = self.question_details[\"fine_print\"]\n",
    "        self.PERPLEXITY_PROMPT1 = \"\"\"\n",
    "You are an assistant to a superforecaster.\n",
    "You will be given the Independent Forecasting Problem, Resolution Criteria, Background and Fine Print.\n",
    "Please generate a concise but detailed rundown of the most relevant news and quantitative data needed to forecast the question.\n",
    "Do not include any forecasts from Metaculus or other prediction market websites.\n",
    "If the questions asks you to estimate a quantity, please estimate the quantity and provide your reasoning for the value.\n",
    "\"\"\"\n",
    "        self.query1 = f\"\"\"\n",
    "Independent Forecasting Problem: [{self.title}]\n",
    "\n",
    "Resolution Criteria: [{self.resolution_criteria}]\n",
    "\n",
    "Background: [{self.background}]\n",
    "\n",
    "Fine Print: [{self.fine_print}]\n",
    "\"\"\"\n",
    "        self.research1 = perplexity(self.PERPLEXITY_PROMPT1, self.query1)\n",
    "\n",
    "        self.OPENAI_PROMPT1 = f\"\"\"\n",
    "You are a professional forecaster predicting an event for a client.\n",
    "Please assign a probability from 1% to 99% for the given event.\n",
    "Pay attention to subclasses when making estimates.  For example, if the question asks for \"light duty electric vehicle sales\", \n",
    "be sure to restrict the focus to the subclass \"light duty\" of \"electric vehicle\", and similarly for other topics.\n",
    "\n",
    "The event in question is:\n",
    "{self.title}\n",
    "\n",
    "Here are observations from your research assistant:\n",
    "{self.research1}\n",
    "\"\"\"       \n",
    "        self.OPENAI_PROMPT1 += f\"\"\"\n",
    "Today is {self.today}.\n",
    "\n",
    "Please summarize your rationale for the forecast under heading \"Rationale\".\n",
    "\n",
    "Please give your final answer as: \"Probability: ZZ%\", where ZZ is an integer between 1 and 99 under heading \"Forecast\".\n",
    "\"\"\"\n",
    "\n",
    "        self.forecast1 = openai(self.client, self.OPENAI_PROMPT1)\n",
    "    \n",
    "        self.PERPLEXITY_PROMPT2 = \"\"\"\n",
    "    You are an assistant to a superforecaster.\n",
    "    The superforecaster has made a prediction.\n",
    "    You will now ofer constructive feedback on the prediction and provide additional information you feel the superforecaster needs in order to refine the prediction.\n",
    "    \"\"\"\n",
    "        self.details = f\"Superforecaster's Prediction: [{self.forecast1}]\"\n",
    "        self.critic1 = perplexity(self.PERPLEXITY_PROMPT2, self.details)\n",
    "    \n",
    "        self.OPENAI_PROMPT2 = f\"\"\"\n",
    "    You are a professional forecaster predicting an event for a client.\n",
    "    \n",
    "    You were given this input: [{self.OPENAI_PROMPT1}]\n",
    "    \n",
    "    You made this forecast: [{self.forecast1}]\n",
    "    \n",
    "    Your assistant gives this feedback: [{self.critic1}]\n",
    "    \n",
    "    Please review the assistant's feedback and revise your prediction.  \n",
    "    Please give a summary under heading \"Forecast\" which is 200 words or less.  \n",
    "    Please give your final answer as: \"Probability: ZZ%\", where ZZ is an integer between 1 and 99.\n",
    "    \"\"\"\n",
    "        self.forecast2 = openai(self.client, self.OPENAI_PROMPT2)\n",
    "      \n",
    "        # Regular expression to find the number following 'Probability: '\n",
    "        self.probability_match = find_number_before_percent(self.forecast2)\n",
    "    \n",
    "        # Extract the number if a match is found\n",
    "        self.prediction = None\n",
    "        if self.probability_match:\n",
    "            self.prediction = int(self.probability_match) # int(match.group(1))\n",
    "            print(f\"The extracted probability is: {self.prediction}%\")\n",
    "            self.prediction = min(max(self.prediction, 1), 99) # To prevent extreme forecasts\n",
    "    \n",
    "        self.comment = self.forecast2\n",
    "        \n",
    "    def report(self):\n",
    "        rpt = f\"\"\"\n",
    "# {self.question_id} {self.question_details['title']}\n",
    "\n",
    "{self.comment}\n",
    "\"\"\"\n",
    "        return rpt\n",
    "\n",
    "    def upload(self):\n",
    "        post_question_prediction(self.question_id, self.prediction)\n",
    "        post_question_comment(self.question_id, self.comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = 4914"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = Forecaster(pid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extracted probability is: 50%\n"
     ]
    }
   ],
   "source": [
    "self.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Forecast\n",
      "\n",
      "Considering the available data and feedback, it’s essential to refine the forecast for Donald Trump's search interest in July 2024. The historical drop post-2016, stabilizing at 25%, serves as a baseline. The June 27, 2024, debate likely spiked interest, which might moderate through July but still remain elevated due to the proximity of the September 10, 2024, debate and the ongoing presidential election cycle. Additional analysis of Gallup's favorability ratings and partial Google Trends data from July 18, 2024, also reflects continuing public engagement. While considering Google's overwhelming market share, the influence of other search engines should not be ignored but remains minimal. Factoring in these elements, the dynamic nature of Trump’s political involvement, and public opinion metrics, it seems probable that the search interest will be higher than initially expected, potentially reaching up to 50% of the November 2016 peak.\n",
      "\n",
      "### Probability\n",
      "Probability: 50%\n"
     ]
    }
   ],
   "source": [
    "print(self.comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get IFP ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifps = list_questions()['results']\n",
    "today_ids = list(sorted([x['id'] for x in ifps]))\n",
    "# today_ids = [25876, 25877, 25875, 25873, 25871, 25878, 25874, 25872] # 08JUL24\n",
    "# today_ids = [26006, 25936, 25935, 25934, 25933, 26004, 26005] # 09JUL24\n",
    "# today_ids = [25955, 25956, 25957, 25960, 25959, 25954, 25953, 25952, 25958] # 10JUL24\n",
    "# today_ids = [26019, 26018, 26017, 26020, 26022, 26021, 26023, 26024] # 11JUL24\n",
    "# today_ids = [26095, 26096, 26097, 26098, 26099, 26100, 26101, 26102] # 12JUL24\n",
    "# today_ids = [26133, 26134, 26138, 26139, 26140, 26157, 26158, 26159] # 15JUL24\n",
    "# today_ids = [26189, 26190, 26191, 26192, 26193, 26194, 26195, 26196] # 16JUL24\n",
    "# today_ids = [26210, 26211, 26212, 26213, 26214, 26215, 26216] # 17JUL24\n",
    "# today_ids = [26232, 26233, 26234, 26235, 26236] # 18JUL24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26232, 26233, 26234, 26235, 26236]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████▌                                                          | 1/5 [00:31<02:07, 31.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extracted probability is: 15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████▏                                           | 2/5 [00:57<01:24, 28.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extracted probability is: 90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████▊                             | 3/5 [01:33<01:03, 31.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extracted probability is: 55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████▍              | 4/5 [02:03<00:31, 31.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extracted probability is: 70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 5/5 [02:32<00:00, 30.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extracted probability is: 75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "for question_id in tqdm(today_ids):\n",
    "    try:\n",
    "        predictions[question_id]\n",
    "    except:\n",
    "        forecaster = Forecaster(question_id)\n",
    "        forecaster.predict()\n",
    "        predictions[question_id] = forecaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "===========================================================================================================\n",
       "# 26232 Will the US government end its agreement directly allowing Verisign to manage the authoritative domain name registry for the .com TLD, before August 3, 2024?\n",
       "\n",
       "### Forecast\n",
       "\n",
       "Upon reviewing the assistant’s feedback:\n",
       "\n",
       "1. **Automatic Renewal Clause**: While the automatic renewal clause is a significant hurdle, termination due to material breach or legal decisions remains a possibility.\n",
       "2. **Advocacy Efforts**: The American Economic Liberties Project and other groups are making targeted pushes against Verisign, indicating organized efforts.\n",
       "3. **Biden Administration**: Broader policy goals on promoting competition may influence the decision, though no specific actions or statements on Verisign and the .com TLD have been noted.\n",
       "4. **Controversies and Criticism**: Allegations of price-gouging and kickbacks with ICANN are serious and could impact future decisions.\n",
       "5. **ICANN and Verisign's Relationship**: The established partnership is a stabilizing factor, but ICANN’s role in internet governance could be influenced by external pressures and investigations.\n",
       "\n",
       "Given these complexities, advocacy, and potential antitrust investigations, the probability of the US government ending its agreement with Verisign before August 3, 2024, might be somewhat higher than initially assessed, although still limited by bureaucratic processes and established partnerships.\n",
       "\n",
       "### Forecast\n",
       "\n",
       "Probability: 15%\n",
       "===========================================================================================================\n",
       "\n",
       "===========================================================================================================\n",
       "# 26233 Will the domestic box office opening of \"Deadpool & Wolverine\" be higher than that of \"Deadpool\" and \"The Wolverine\" combined?\n",
       "\n",
       "### Forecast\n",
       "\n",
       "Based on the feedback and additional information provided, revising the forecast to incorporate a slightly higher probability is justified. The majority of projections from reputable sources uniformly suggest an opening in the range of $160 million to $165 million, with some optimistic estimates reaching up to $239 million. The combined historical opening of \"Deadpool\" and \"The Wolverine\" stands at $185,548,391, providing a solid benchmark.\n",
       "\n",
       "The strongest day-one ticket pre-sales reported by Fandango for 2024, surpassing even major titles like \"Guardians of the Galaxy Vol. 3\" and \"Black Panther: Wakanda Forever,\" indicate substantial public interest. The return of Hugh Jackman as Wolverine and the popularity of the characters, along with the successful history of previous films in the series, further reinforce the likelihood of a strong performance.\n",
       "\n",
       "Given these consistent projections, strong ticket pre-sales, and historical success, it is highly probable that \"Deadpool & Wolverine\" will surpass the combined openings of \"Deadpool\" (2016) and \"The Wolverine\" (2013).\n",
       "\n",
       "Probability: 90%\n",
       "===========================================================================================================\n",
       "\n",
       "===========================================================================================================\n",
       "# 26234 Will an avian influenza virus in humans be declared a “Public Health Emergency of International Concern” by the World Health Organization before Sept 30, 2024?\n",
       "\n",
       "### Forecast:\n",
       "\n",
       "Reviewing the feedback, we've considered the assistant's suggestion to incorporate more specific numbers and trends from recent reports. The report mentions a case fatality rate of 56% for avian influenza A(H5) viruses, which is significant. The jump of HPAI A(H5N1) to dairy cattle in the U.S. increases concerns about human transmissibility. Enhanced surveillance efforts by WHO and other health organizations, such as WOAH and FAO, indicate high vigilance. Although sustained human-to-human transmission is less evident, the virus's potential to increase transmissibility through mutations remains a concern. The recent detection of other avian influenza strains (A(H10N3) and A(H10N5)) underscores ongoing risks. Given this information, the reasonable probability of a WHO declaration by September 30, 2024, is revised upwards due to heightened alertness and recent developments.\n",
       "\n",
       "### Final Answer:\n",
       "Probability: 55%\n",
       "===========================================================================================================\n",
       "\n",
       "===========================================================================================================\n",
       "# 26235 Will the Warren Buffett Indicator exceed 200% before September 17, 2024?\n",
       "\n",
       "\n",
       "### Forecast\n",
       "\n",
       "Upon reviewing the assistant’s feedback and incorporating additional considerations, including the historical context, inherent market volatility, and potential upcoming catalysts, it remains prudent to account for these variables' impact.\n",
       "\n",
       "As of July 10, 2024, the Warren Buffett Indicator stands close to 200% at 196.20%. Its persistence above 190% since May 2024 suggests a sustained trend of market overvaluation relative to GDP. Historical peaks before significant market corrections and the likelihood of volatile economic conditions in the run-up to September 17, 2024, also play critical roles.\n",
       "\n",
       "Upcoming market events, earnings reports, and economic data releases bear significant influence, and even minor market fluctuations could easily breach the 200% threshold.\n",
       "\n",
       "Given the proximity of the indicator to the crucial mark and the factors mentioned, the probability still appears high but should be tempered slightly to reflect potential rapid reversals or corrections.\n",
       "\n",
       "### Probability\n",
       "\n",
       "Probability: 70%\n",
       "===========================================================================================================\n",
       "\n",
       "===========================================================================================================\n",
       "# 26236 Will at least 24 world records be broken at the 2024 Paris Olympics?\n",
       "\n",
       "### Forecast\n",
       "\n",
       "The likelihood of at least 24 world records being broken at the 2024 Paris Olympics can be refined by considering detailed insights:\n",
       "\n",
       "1. **Historical Trends**: Past Summer Olympics generally see around mid-20s world records broken, indicating a plausible range.\n",
       "2. **Current Athlete Performance**: Athletes like Katie Ledecky and the potential for records from events like swimming and track.\n",
       "3. **Olympic Records That Are Also World Records**: Specific high-profile events and current athletes holding these records show promising potential.\n",
       "4. **Heat Conditions**: While heat waves could impact endurance events, many events aren't as affected.\n",
       "5. **Sport-Specific Factors**: Advancements in technology, particularly the new Olympic track expected to be very fast, and initiatives to mitigate adverse weather effects.\n",
       "\n",
       "Given these considerations and the additional insights on technological advancements and event-specific potentials, the probability is adjusted to reflect a higher likelihood.\n",
       "\n",
       "### Forecast\n",
       "\n",
       "Probability: 75%\n",
       "===========================================================================================================\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rpt = \"\"\n",
    "for p in predictions.values():\n",
    "    rpt += f\"\"\"\n",
    "===========================================================================================================\n",
    "# {p.question_id} {p.title}\n",
    "\n",
    "{p.comment}\n",
    "===========================================================================================================\n",
    "\"\"\"\n",
    "\n",
    "from IPython.display import Markdown\n",
    "display(Markdown(rpt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "KbQ6dmk9gzfk",
    "outputId": "b9984bbc-d145-4a6b-9c29-f21f70c6cbf0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████▌                                                          | 1/5 [00:00<00:02,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction posted for  26232\n",
      "Comment posted for  26232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████▏                                           | 2/5 [00:01<00:01,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction posted for  26233\n",
      "Comment posted for  26233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████████████▊                             | 3/5 [00:01<00:01,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction posted for  26234\n",
      "Comment posted for  26234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████▍              | 4/5 [00:02<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction posted for  26235\n",
      "Comment posted for  26235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 5/5 [00:02<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction posted for  26236\n",
      "Comment posted for  26236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for p in tqdm(predictions.values()):\n",
    "    p.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
